{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "__PYCbUTQC49",
        "YPMawDrYnNIe",
        "E3Obdo-KKb6K",
        "ti6Ls2TbsAl6",
        "tf0OSbNTvxBB",
        "0ATWYNlJv71-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9669d034ccb948d8b0cbcf2e777a628d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d0618b3f02f481c8d82f00e5751fdef",
              "IPY_MODEL_875d2ede87bc4d4ba4520df59b5a2310",
              "IPY_MODEL_07fcf6453e844ba09e5ee0dcf5254181"
            ],
            "layout": "IPY_MODEL_ced96465655448baa5e1be37cb7b9ca4"
          }
        },
        "0d0618b3f02f481c8d82f00e5751fdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5007cd77433e4125a2c5eca8ccc00d1e",
            "placeholder": "​",
            "style": "IPY_MODEL_18f4c7bad9db4eba9770a2eb642a3612",
            "value": "Downloading: 100%"
          }
        },
        "875d2ede87bc4d4ba4520df59b5a2310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a28b4b496b146bf90c58828d2370e7b",
            "max": 379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa36970d632a4ab390c1971c3a7877f4",
            "value": 379
          }
        },
        "07fcf6453e844ba09e5ee0dcf5254181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7c423fcad84ef4b68ec451afdceb58",
            "placeholder": "​",
            "style": "IPY_MODEL_731472fd8eec4114ba217fef96261162",
            "value": " 379/379 [00:00&lt;00:00, 22.5kB/s]"
          }
        },
        "ced96465655448baa5e1be37cb7b9ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5007cd77433e4125a2c5eca8ccc00d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f4c7bad9db4eba9770a2eb642a3612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a28b4b496b146bf90c58828d2370e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa36970d632a4ab390c1971c3a7877f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab7c423fcad84ef4b68ec451afdceb58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "731472fd8eec4114ba217fef96261162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "160b626d7cac4ae4aeea86434384314c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9950eee9a7cb4c5b8c60f9a7b3bdf549",
              "IPY_MODEL_603314e40b664fc496f7e5c9a3af980c",
              "IPY_MODEL_c2db2a5e168c427e8bc43265db2497d5"
            ],
            "layout": "IPY_MODEL_35c1d0b4305044c896bb38538775dfb4"
          }
        },
        "9950eee9a7cb4c5b8c60f9a7b3bdf549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9dd928953c4782a07a67b03852ea17",
            "placeholder": "​",
            "style": "IPY_MODEL_3e9f63ad886248d5a87999c1439238af",
            "value": "Downloading: 100%"
          }
        },
        "603314e40b664fc496f7e5c9a3af980c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77e66c5977e40c48e31d376754ba56d",
            "max": 576,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_538aaec5014e4ec380fc44f785186980",
            "value": 576
          }
        },
        "c2db2a5e168c427e8bc43265db2497d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e024108568024cbdb5f80c05e0c8eef2",
            "placeholder": "​",
            "style": "IPY_MODEL_f5ec3f2ed3b54cf08789c4e067fe2512",
            "value": " 576/576 [00:00&lt;00:00, 30.7kB/s]"
          }
        },
        "35c1d0b4305044c896bb38538775dfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9dd928953c4782a07a67b03852ea17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e9f63ad886248d5a87999c1439238af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b77e66c5977e40c48e31d376754ba56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538aaec5014e4ec380fc44f785186980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e024108568024cbdb5f80c05e0c8eef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ec3f2ed3b54cf08789c4e067fe2512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f956d4c66264d46849c09cfceb03fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f9d35432f91426fb870cb91874ce8be",
              "IPY_MODEL_ddd7f62e560747d7aa2632d87a0f0d93",
              "IPY_MODEL_41cc0b1fcd1b4b93b78b9f40212290a7"
            ],
            "layout": "IPY_MODEL_ef5a80041541491bb1acdef19cfefc4f"
          }
        },
        "9f9d35432f91426fb870cb91874ce8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2b7501d75b4dec98a4e2cbcc78283d",
            "placeholder": "​",
            "style": "IPY_MODEL_62153a88b7d849f5b8292ce28d41aab0",
            "value": "Downloading: 100%"
          }
        },
        "ddd7f62e560747d7aa2632d87a0f0d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c41e63ef0bd542f19f8a1273039f7c36",
            "max": 780034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8706c6caa6f944599b4edec0af84f5c0",
            "value": 780034
          }
        },
        "41cc0b1fcd1b4b93b78b9f40212290a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02fd72a479994786a1d1e81ed9790ebf",
            "placeholder": "​",
            "style": "IPY_MODEL_faece2e8f2fa4eb58ccbcbe3e913b962",
            "value": " 780k/780k [00:00&lt;00:00, 528kB/s]"
          }
        },
        "ef5a80041541491bb1acdef19cfefc4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2b7501d75b4dec98a4e2cbcc78283d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62153a88b7d849f5b8292ce28d41aab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c41e63ef0bd542f19f8a1273039f7c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8706c6caa6f944599b4edec0af84f5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02fd72a479994786a1d1e81ed9790ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faece2e8f2fa4eb58ccbcbe3e913b962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a09184cdd809496789732d543223159f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90b8ca924a094e70a42827f8dfac811d",
              "IPY_MODEL_fe044260006d4c398f57fad39b556acd",
              "IPY_MODEL_68906285162949e29135898588e0036b"
            ],
            "layout": "IPY_MODEL_f4be05cc7587422a887df9e3fae66385"
          }
        },
        "90b8ca924a094e70a42827f8dfac811d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_143e436e93124f43bac28543f208b0cb",
            "placeholder": "​",
            "style": "IPY_MODEL_a8d9b74701da48cdbdc15d198627c329",
            "value": "Downloading: 100%"
          }
        },
        "fe044260006d4c398f57fad39b556acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a8a507584a438d9e59ec6db77dc6d9",
            "max": 2697421,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7f56e6e84bf45b7a804e5bb6d0f6edb",
            "value": 2697421
          }
        },
        "68906285162949e29135898588e0036b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d657b7cd58034803810b0bf240c4acf9",
            "placeholder": "​",
            "style": "IPY_MODEL_1b5a1e7b71164a5ba3a091a55538d3ed",
            "value": " 2.70M/2.70M [00:01&lt;00:00, 1.81MB/s]"
          }
        },
        "f4be05cc7587422a887df9e3fae66385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143e436e93124f43bac28543f208b0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d9b74701da48cdbdc15d198627c329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2a8a507584a438d9e59ec6db77dc6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f56e6e84bf45b7a804e5bb6d0f6edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d657b7cd58034803810b0bf240c4acf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5a1e7b71164a5ba3a091a55538d3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52b25c58e30a41c6b2ed3ec9812d6fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08204929c7194d3caecf0eab378aabb2",
              "IPY_MODEL_bc0e8d6b7a5e4968a82556f68a8c68eb",
              "IPY_MODEL_1278ba7964d3425dbdcc07a2a8691c5e"
            ],
            "layout": "IPY_MODEL_3a454bc9bb0e4fb7a75956de5aa1322b"
          }
        },
        "08204929c7194d3caecf0eab378aabb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53cd43affb5244ceb1ada83e6285597a",
            "placeholder": "​",
            "style": "IPY_MODEL_658ce1d5d271406394157534f5f9d93f",
            "value": "Downloading: 100%"
          }
        },
        "bc0e8d6b7a5e4968a82556f68a8c68eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd5d0c06640e407b81921e32c3eb6281",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c5f95119df840da8ebeaa0b4e5f24c5",
            "value": 112
          }
        },
        "1278ba7964d3425dbdcc07a2a8691c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_165e52586ddc4de8b469367c4f79b17f",
            "placeholder": "​",
            "style": "IPY_MODEL_8704fcba91124b649b800ee5cf69d464",
            "value": " 112/112 [00:00&lt;00:00, 2.02kB/s]"
          }
        },
        "3a454bc9bb0e4fb7a75956de5aa1322b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53cd43affb5244ceb1ada83e6285597a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658ce1d5d271406394157534f5f9d93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd5d0c06640e407b81921e32c3eb6281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5f95119df840da8ebeaa0b4e5f24c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "165e52586ddc4de8b469367c4f79b17f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8704fcba91124b649b800ee5cf69d464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTS2C5a0Mdch",
        "outputId": "ed68a05e-4643-437b-98ea-ab68295212d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.6)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "!pip install gensim spacy nltk\n",
        "import re \n",
        "import gensim\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dek5aCWdNAM8",
        "outputId": "59abc2d5-97d9-4048-ec66-84f15edeef18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('/content/drive/My Drive/Bachelor/Cleaned Data/Sarcasm.csv') "
      ],
      "metadata": {
        "id": "Lmo4neG-OfsV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "max_sequence_length = np.max(data['Number of Words in tweet'])\n",
        "print(\"max length is:\", max_sequence_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeYcAwqjOhPh",
        "outputId": "03b13208-5f7c-41dd-ff7d-69e40d40840e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length is: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = data['cleaned_tweet']\n",
        "label = data['sarcasm']"
      ],
      "metadata": {
        "id": "CbbKvvYxOiKo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=30000)\n",
        "tokenizer.fit_on_texts(text.astype(str))\n",
        "sequences = tokenizer.texts_to_sequences(text.astype(str))\n",
        "\n",
        "word_index = tokenizer.word_index   # a dictionary of each word and its index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "print('Shape of data tensor:', data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bu_FkO8OjTa",
        "outputId": "00f29f75-c3a5-476b-b726-5a3e5bec4e59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 55395 unique tokens.\n",
            "Shape of data tensor: (26095, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "labels = to_categorical(np.asarray(label))  ## one hot of the output\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3emOVuXOqwy",
        "outputId": "b6db8398-e8cf-4ff0-ace1-a0b279278c2d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (26095, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "i1IEF0VpO4GH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "scboZpXEO9sx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arabert"
      ],
      "metadata": {
        "id": "__PYCbUTQC49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install pyarabic\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T9dar5-QFlV",
        "outputId": "8b20ab03-669e-4355-f722-33777a442b2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=008b93d7316ecacfb05cc17c624de69ae1637a5061352a62f62641e4856846bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a4/72/df07592cea3ae06b5e846f5e52262f8b16748e829ca354b7df\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=9efcb7130f4a1d2fe7a9c34f6feb758018cd6b16c7a89b262f0d371efd15727f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f3/85/b8cf1d8bfe55dc2ece0f1fcd4e91d6f8fc7b59ff3fd75329e1\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=579a6c78a3271bfafa89c2b53144c3384add9c6704fafdc00b6707c1d0e657fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/26/e9/df16869ccbd4abf517f1ff3be9a2c7ee5c5980fc87eea04fb1\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 600, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (600/600), 9.14 MiB | 7.38 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HPB_5gUGQK8Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoemK47uQPkJ",
        "outputId": "a79e93c4-8c55-4c49-bfd0-a13a36be5cbd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arabert_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv01\",do_lower_case=False)\n",
        "def encode_sentence(sent):\n",
        "    tokenized = arabert_tokenizer.tokenize(sent)\n",
        "    return arabert_tokenizer.convert_tokens_to_ids(tokenized)"
      ],
      "metadata": {
        "id": "nXHxjYL6QRIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "9669d034ccb948d8b0cbcf2e777a628d",
            "0d0618b3f02f481c8d82f00e5751fdef",
            "875d2ede87bc4d4ba4520df59b5a2310",
            "07fcf6453e844ba09e5ee0dcf5254181",
            "ced96465655448baa5e1be37cb7b9ca4",
            "5007cd77433e4125a2c5eca8ccc00d1e",
            "18f4c7bad9db4eba9770a2eb642a3612",
            "3a28b4b496b146bf90c58828d2370e7b",
            "fa36970d632a4ab390c1971c3a7877f4",
            "ab7c423fcad84ef4b68ec451afdceb58",
            "731472fd8eec4114ba217fef96261162",
            "160b626d7cac4ae4aeea86434384314c",
            "9950eee9a7cb4c5b8c60f9a7b3bdf549",
            "603314e40b664fc496f7e5c9a3af980c",
            "c2db2a5e168c427e8bc43265db2497d5",
            "35c1d0b4305044c896bb38538775dfb4",
            "7d9dd928953c4782a07a67b03852ea17",
            "3e9f63ad886248d5a87999c1439238af",
            "b77e66c5977e40c48e31d376754ba56d",
            "538aaec5014e4ec380fc44f785186980",
            "e024108568024cbdb5f80c05e0c8eef2",
            "f5ec3f2ed3b54cf08789c4e067fe2512",
            "6f956d4c66264d46849c09cfceb03fda",
            "9f9d35432f91426fb870cb91874ce8be",
            "ddd7f62e560747d7aa2632d87a0f0d93",
            "41cc0b1fcd1b4b93b78b9f40212290a7",
            "ef5a80041541491bb1acdef19cfefc4f",
            "2d2b7501d75b4dec98a4e2cbcc78283d",
            "62153a88b7d849f5b8292ce28d41aab0",
            "c41e63ef0bd542f19f8a1273039f7c36",
            "8706c6caa6f944599b4edec0af84f5c0",
            "02fd72a479994786a1d1e81ed9790ebf",
            "faece2e8f2fa4eb58ccbcbe3e913b962",
            "a09184cdd809496789732d543223159f",
            "90b8ca924a094e70a42827f8dfac811d",
            "fe044260006d4c398f57fad39b556acd",
            "68906285162949e29135898588e0036b",
            "f4be05cc7587422a887df9e3fae66385",
            "143e436e93124f43bac28543f208b0cb",
            "a8d9b74701da48cdbdc15d198627c329",
            "b2a8a507584a438d9e59ec6db77dc6d9",
            "a7f56e6e84bf45b7a804e5bb6d0f6edb",
            "d657b7cd58034803810b0bf240c4acf9",
            "1b5a1e7b71164a5ba3a091a55538d3ed",
            "52b25c58e30a41c6b2ed3ec9812d6fd7",
            "08204929c7194d3caecf0eab378aabb2",
            "bc0e8d6b7a5e4968a82556f68a8c68eb",
            "1278ba7964d3425dbdcc07a2a8691c5e",
            "3a454bc9bb0e4fb7a75956de5aa1322b",
            "53cd43affb5244ceb1ada83e6285597a",
            "658ce1d5d271406394157534f5f9d93f",
            "bd5d0c06640e407b81921e32c3eb6281",
            "0c5f95119df840da8ebeaa0b4e5f24c5",
            "165e52586ddc4de8b469367c4f79b17f",
            "8704fcba91124b649b800ee5cf69d464"
          ]
        },
        "outputId": "198043dc-bc81-4d16-ef0d-f577b891fe3c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/379 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9669d034ccb948d8b0cbcf2e777a628d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/576 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "160b626d7cac4ae4aeea86434384314c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f956d4c66264d46849c09cfceb03fda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.70M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a09184cdd809496789732d543223159f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52b25c58e30a41c6b2ed3ec9812d6fd7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200"
      ],
      "metadata": {
        "id": "KtdtQlpjQScU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "EAH8636NqqA1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU-BiLSTM"
      ],
      "metadata": {
        "id": "YPMawDrYnNIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7JOyU_2mJgW",
        "outputId": "e30c33bc-777f-4d42-f401-792c03bf0770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 17s 20ms/step - loss: 0.4715 - accuracy: 0.8203\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.2764 - accuracy: 0.8849\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.1423 - accuracy: 0.9496\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0860 - accuracy: 0.9722\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0574 - accuracy: 0.9826\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0429 - accuracy: 0.9874\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 14s 24ms/step - loss: 0.0352 - accuracy: 0.9899\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0312 - accuracy: 0.9909\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0268 - accuracy: 0.9921\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0258 - accuracy: 0.9922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faebafb6610>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions= model.predict(x_test)\n",
        "\n",
        "predictions=np.argmax(predictions, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDf12dpGmKSd",
        "outputId": "621be7bd-15f1-47db-849a-212ef24bf18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.905\n",
            "The Confusion Matrix is [[5306   75]\n",
            " [ 109 1033]]\n",
            "Accuracy: 0.972\n",
            "F1 Score: 0.918\n",
            "Precision: 0.932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BSclxZnpn1ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM, adding a flatten layer\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model1= tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3mS7Qlbn1lI",
        "outputId": "fba3bb8f-bb62-4a87-81c3-e48b630fb917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 20s 23ms/step - loss: 0.4761 - accuracy: 0.8171\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 13s 22ms/step - loss: 0.2749 - accuracy: 0.8890\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1387 - accuracy: 0.9504\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0794 - accuracy: 0.9750\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0509 - accuracy: 0.9847\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0406 - accuracy: 0.9884\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.0338 - accuracy: 0.9905\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.0304 - accuracy: 0.9911\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0260 - accuracy: 0.9920\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0247 - accuracy: 0.9921\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faeb89e5e80>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1= model1.predict(x_test)\n",
        "\n",
        "predictions1=np.argmax(predictions1, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions1))\n",
        "cm = confusion_matrix(y_test, predictions1)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions1))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions1))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAKLM0E9onLY",
        "outputId": "1abaf406-13b3-44f3-f332-3ebe1274db6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.903\n",
            "The confusion matrix is [[5305   70]\n",
            " [ 111 1037]]\n",
            "Accuracy: 0.972\n",
            "F1 Score: 0.920\n",
            "Precision: 0.937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A37FcII1o8DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM with a flatten layer and also a Softmax activation function for classification, but with a RMSprop optimizer\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PuQpnctpWEw",
        "outputId": "2d94f228-bb09-4b09-9bb4-c37af4013a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 18s 19ms/step - loss: 0.4796 - accuracy: 0.8182\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.4074 - accuracy: 0.8265\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 14s 24ms/step - loss: 0.3426 - accuracy: 0.8551\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.3116 - accuracy: 0.8710\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.2865 - accuracy: 0.8845\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 9s 15ms/step - loss: 0.2643 - accuracy: 0.8964\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2429 - accuracy: 0.9060\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2230 - accuracy: 0.9163\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 8s 14ms/step - loss: 0.2025 - accuracy: 0.9250\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 8s 14ms/step - loss: 0.1837 - accuracy: 0.9319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faeb42a5340>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2= model2.predict(x_test)\n",
        "\n",
        "predictions2=np.argmax(predictions2, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions2))\n",
        "cm = confusion_matrix(y_test, predictions2)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions2))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions2))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVvIfNZipmLk",
        "outputId": "0189e510-033e-4a33-f694-91936cfb45ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.719\n",
            "The Confusion Matrix is [[5205  173]\n",
            " [ 322  823]]\n",
            "Accuracy: 0.924\n",
            "F1 Score: 0.769\n",
            "Precision: 0.826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "izSznbIkpwPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learning Rate & Optimizers Tuning"
      ],
      "metadata": {
        "id": "E3Obdo-KKb6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU - BiLSTM, Adam(1e-4)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model6.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model6.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy6= model6.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy6)\n",
        "\n",
        "predictions6= model6.predict(x_test)\n",
        "\n",
        "predictions6=np.argmax(predictions6, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions6))\n",
        "cm = confusion_matrix(y_test, predictions6)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions6))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions6))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions6))"
      ],
      "metadata": {
        "id": "ZRyTBy5Wc4zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c01a1e-bf9d-462b-ac38-d0489b7fca5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "612/612 [==============================] - 15s 18ms/step - loss: 0.4703 - accuracy: 0.8190 - get_f1: 0.8190\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.2736 - accuracy: 0.8856 - get_f1: 0.8855\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1403 - accuracy: 0.9492 - get_f1: 0.9492\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0818 - accuracy: 0.9733 - get_f1: 0.9733\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0537 - accuracy: 0.9847 - get_f1: 0.9847\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0405 - accuracy: 0.9887 - get_f1: 0.9887\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0342 - accuracy: 0.9897 - get_f1: 0.9897\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0296 - accuracy: 0.9915 - get_f1: 0.9915\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0278 - accuracy: 0.9919 - get_f1: 0.9919\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.0249 - accuracy: 0.9921 - get_f1: 0.9921\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4545 - accuracy: 0.9045 - get_f1: 0.9045\n",
            "test accuracy is:  [0.4544867277145386, 0.9044917821884155, 0.9044797420501709]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.704\n",
            "The confusion matrix is [[5092  284]\n",
            " [ 339  808]]\n",
            "Accuracy: 0.904\n",
            "F1 Score: 0.722\n",
            "Precision: 0.740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 7: 1 GRU - BiLSTM , Adam 1e-3\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model7.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model7.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy7= model7.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy7)\n",
        "\n",
        "predictions7= model7.predict(x_test)\n",
        "\n",
        "predictions7=np.argmax(predictions7, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions7))\n",
        "cm = confusion_matrix(y_test, predictions7)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions7))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions7))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions7))"
      ],
      "metadata": {
        "id": "rvAsXraRdBkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4c5ca2-e2b7-4898-ddcb-0ad3e6ef7e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 15s 18ms/step - loss: 0.3744 - accuracy: 0.8480 - get_f1: 0.8480\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1460 - accuracy: 0.9487 - get_f1: 0.9487\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0500 - accuracy: 0.9848 - get_f1: 0.9848\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0222 - accuracy: 0.9922 - get_f1: 0.9922\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0141 - accuracy: 0.9932 - get_f1: 0.9932\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0103 - accuracy: 0.9942 - get_f1: 0.9942\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0113 - accuracy: 0.9937 - get_f1: 0.9937\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0118 - accuracy: 0.9936 - get_f1: 0.9936\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0096 - accuracy: 0.9945 - get_f1: 0.9945\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0086 - accuracy: 0.9952 - get_f1: 0.9952\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.7373 - accuracy: 0.9017 - get_f1: 0.9018\n",
            "test accuracy is:  [0.7373231649398804, 0.901732325553894, 0.9017791748046875]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.740\n",
            "The confusion matrix is [[4983  325]\n",
            " [ 316  899]]\n",
            "Accuracy: 0.902\n",
            "F1 Score: 0.737\n",
            "Precision: 0.734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 7: 1 GRU - BiLSTM , Adam 1e-2\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model8.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-2),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model8.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy8= model8.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy8)\n",
        "\n",
        "predictions8= model8.predict(x_test)\n",
        "\n",
        "predictions8=np.argmax(predictions8, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions8))\n",
        "cm = confusion_matrix(y_test, predictions8)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions8))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions8))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ethbh7jpdBm5",
        "outputId": "a5613433-7214-48a6-b941-4bbf35797a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 15s 18ms/step - loss: 0.3842 - accuracy: 0.8413 - get_f1: 0.8413\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.2029 - accuracy: 0.9194 - get_f1: 0.9194\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1399 - accuracy: 0.9490 - get_f1: 0.9490\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1041 - accuracy: 0.9621 - get_f1: 0.9621\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0837 - accuracy: 0.9702 - get_f1: 0.9701\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0670 - accuracy: 0.9753 - get_f1: 0.9753\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0584 - accuracy: 0.9788 - get_f1: 0.9788\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0520 - accuracy: 0.9807 - get_f1: 0.9807\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0577 - accuracy: 0.9800 - get_f1: 0.9800\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0522 - accuracy: 0.9818 - get_f1: 0.9818\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4986 - accuracy: 0.8850 - get_f1: 0.8851\n",
            "test accuracy is:  [0.49856051802635193, 0.8850222229957581, 0.8850818872451782]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.712\n",
            "The confusion matrix is [[4925  407]\n",
            " [ 343  848]]\n",
            "Accuracy: 0.885\n",
            "F1 Score: 0.693\n",
            "Precision: 0.676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 7: 1 GRU - BiLSTM , Adam 1e-1\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model9 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model9.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-1),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model9.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy9= model9.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy9)\n",
        "\n",
        "predictions9= model9.predict(x_test)\n",
        "\n",
        "predictions9=np.argmax(predictions9, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions9))\n",
        "cm = confusion_matrix(y_test, predictions9)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions9))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions9))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions9))"
      ],
      "metadata": {
        "id": "CMSC0lOId22P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8de9f75-c336-45f0-d63a-e0a3e1ee8a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 15s 18ms/step - loss: 0.5279 - accuracy: 0.8159 - get_f1: 0.8158\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4750 - accuracy: 0.8185 - get_f1: 0.8185\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4755 - accuracy: 0.8185 - get_f1: 0.8184\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.4753 - accuracy: 0.8184 - get_f1: 0.8183\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4753 - accuracy: 0.8185 - get_f1: 0.8184\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.4756 - accuracy: 0.8185 - get_f1: 0.8185\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.4753 - accuracy: 0.8185 - get_f1: 0.8185\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.4756 - accuracy: 0.8185 - get_f1: 0.8184\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.4755 - accuracy: 0.8185 - get_f1: 0.8185\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4749 - accuracy: 0.8185 - get_f1: 0.8185\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4583 - accuracy: 0.8286 - get_f1: 0.8286\n",
            "test accuracy is:  [0.458283007144928, 0.8286064863204956, 0.8286241888999939]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.000\n",
            "The confusion matrix is [[5405    0]\n",
            " [1118    0]]\n",
            "Accuracy: 0.829\n",
            "F1 Score: 0.000\n",
            "Precision: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 7: 1 GRU - BiLSTM , RMSprop 1e-4\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model10 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model10.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model10.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy10= model10.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy10)\n",
        "\n",
        "predictions10= model10.predict(x_test)\n",
        "\n",
        "predictions10=np.argmax(predictions10, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions10))\n",
        "cm = confusion_matrix(y_test, predictions10)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions10))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions10))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENGT5smkGhVB",
        "outputId": "dfe5508b-ac03-4eee-ea3f-34a7195d4ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "612/612 [==============================] - 14s 15ms/step - loss: 0.4794 - accuracy: 0.8192 - get_f1: 0.8192\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 9s 15ms/step - loss: 0.4001 - accuracy: 0.8253 - get_f1: 0.8253\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.3418 - accuracy: 0.8565 - get_f1: 0.8565\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.3126 - accuracy: 0.8735 - get_f1: 0.8736\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2876 - accuracy: 0.8841 - get_f1: 0.8841\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2670 - accuracy: 0.8948 - get_f1: 0.8948\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2470 - accuracy: 0.9053 - get_f1: 0.9053\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2293 - accuracy: 0.9132 - get_f1: 0.9132\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2130 - accuracy: 0.9209 - get_f1: 0.9208\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2002 - accuracy: 0.9257 - get_f1: 0.9257\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.3635 - accuracy: 0.8611 - get_f1: 0.8611\n",
            "test accuracy is:  [0.36351677775382996, 0.8611068725585938, 0.861128032207489]\n",
            "204/204 [==============================] - 3s 5ms/step\n",
            "Recall: 0.554\n",
            "The confusion matrix is [[4983  396]\n",
            " [ 510  634]]\n",
            "Accuracy: 0.861\n",
            "F1 Score: 0.583\n",
            "Precision: 0.616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 7: 1 GRU - BiLSTM , RMSprop 1e-3\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model11 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model11.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model11.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy11= model11.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy11)\n",
        "\n",
        "predictions11= model11.predict(x_test)\n",
        "\n",
        "predictions11=np.argmax(predictions11, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions11))\n",
        "cm = confusion_matrix(y_test, predictions11)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions11))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions11))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions11))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHDAI4WqGmcJ",
        "outputId": "f8ff1b96-5ede-494f-c832-4393b470da6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 13s 14ms/step - loss: 0.3982 - accuracy: 0.8362 - get_f1: 0.8363\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2537 - accuracy: 0.9061 - get_f1: 0.9061\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.1728 - accuracy: 0.9377 - get_f1: 0.9376\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.1228 - accuracy: 0.9575 - get_f1: 0.9575\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 10s 16ms/step - loss: 0.0922 - accuracy: 0.9679 - get_f1: 0.9679\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0701 - accuracy: 0.9767 - get_f1: 0.9767\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0543 - accuracy: 0.9829 - get_f1: 0.9829\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0440 - accuracy: 0.9862 - get_f1: 0.9862\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0357 - accuracy: 0.9895 - get_f1: 0.9895\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0301 - accuracy: 0.9906 - get_f1: 0.9905\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4252 - accuracy: 0.8852 - get_f1: 0.8852\n",
            "test accuracy is:  [0.42520275712013245, 0.8851755261421204, 0.8852351307868958]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.726\n",
            "The confusion matrix is [[4933  432]\n",
            " [ 317  841]]\n",
            "Accuracy: 0.885\n",
            "F1 Score: 0.692\n",
            "Precision: 0.661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 7: 1 GRU - BiLSTM , RMSprop 1e-2\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model12 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model12.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-2),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model12.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy12= model12.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy12)\n",
        "\n",
        "predictions12= model12.predict(x_test)\n",
        "\n",
        "predictions12=np.argmax(predictions12, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions12))\n",
        "cm = confusion_matrix(y_test, predictions12)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions12))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions12))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj1U-PFdGmee",
        "outputId": "c9d6eab1-efb2-458a-a544-f1c7cce2d7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 14s 15ms/step - loss: 0.3952 - accuracy: 0.8427 - get_f1: 0.8428\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.1977 - accuracy: 0.9316 - get_f1: 0.9316\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.1213 - accuracy: 0.9641 - get_f1: 0.9641\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0896 - accuracy: 0.9753 - get_f1: 0.9753\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0697 - accuracy: 0.9814 - get_f1: 0.9814\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0626 - accuracy: 0.9848 - get_f1: 0.9848\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0576 - accuracy: 0.9857 - get_f1: 0.9857\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0523 - accuracy: 0.9889 - get_f1: 0.9889\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0490 - accuracy: 0.9893 - get_f1: 0.9893\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.0472 - accuracy: 0.9894 - get_f1: 0.9894\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 1.0703 - accuracy: 0.8567 - get_f1: 0.8566\n",
            "test accuracy is:  [1.070259690284729, 0.8566610217094421, 0.856628954410553]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.783\n",
            "The confusion matrix is [[4676  682]\n",
            " [ 253  912]]\n",
            "Accuracy: 0.857\n",
            "F1 Score: 0.661\n",
            "Precision: 0.572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 7: 1 GRU - BiLSTM , RMSprop 1e-1\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model13 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model13.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-1),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model13.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy13= model13.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy13)\n",
        "\n",
        "predictions13= model13.predict(x_test)\n",
        "\n",
        "predictions13=np.argmax(predictions13, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions13))\n",
        "cm = confusion_matrix(y_test, predictions13)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions13))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions13))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgLrAHMuGmgo",
        "outputId": "97bb8571-b438-4ee1-c744-57ddfb8eeeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 14s 14ms/step - loss: 0.8879 - accuracy: 0.8011 - get_f1: 0.8011\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.5118 - accuracy: 0.8168 - get_f1: 0.8168\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.5158 - accuracy: 0.8157 - get_f1: 0.8157\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.5169 - accuracy: 0.8180 - get_f1: 0.8179\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.5075 - accuracy: 0.8186 - get_f1: 0.8187\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.5136 - accuracy: 0.8183 - get_f1: 0.8183\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.5601 - accuracy: 0.8158 - get_f1: 0.8157\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.5252 - accuracy: 0.8180 - get_f1: 0.8179\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 9s 15ms/step - loss: 0.5033 - accuracy: 0.8188 - get_f1: 0.8187\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.5004 - accuracy: 0.8187 - get_f1: 0.8187\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4661 - accuracy: 0.8254 - get_f1: 0.8254\n",
            "test accuracy is:  [0.46612268686294556, 0.8253871202468872, 0.825378954410553]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.000\n",
            "The confusion matrix is [[5384    0]\n",
            " [1139    0]]\n",
            "Accuracy: 0.825\n",
            "F1 Score: 0.000\n",
            "Precision: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nK_YA4EYGmjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 8: 1 GRU - BiLSTM / flatten\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model7.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model7.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERHFP1eNd24S",
        "outputId": "8d1e0cc2-e92d-4017-f2ee-f045b3e00aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 19s 22ms/step - loss: 0.4805 - accuracy: 0.8139 - get_f1: 0.8138\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.2780 - accuracy: 0.8877 - get_f1: 0.8877\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.1419 - accuracy: 0.9497 - get_f1: 0.9497\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0820 - accuracy: 0.9738 - get_f1: 0.9739\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.0532 - accuracy: 0.9838 - get_f1: 0.9837\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0409 - accuracy: 0.9881 - get_f1: 0.9881\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0340 - accuracy: 0.9901 - get_f1: 0.9901\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0300 - accuracy: 0.9916 - get_f1: 0.9916\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0271 - accuracy: 0.9920 - get_f1: 0.9920\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0255 - accuracy: 0.9924 - get_f1: 0.9924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8d946b3150>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy7= model7.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "626LqkvqeCdL",
        "outputId": "29fd424a-2596-454b-bf7f-fbce2ce03454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 2s 6ms/step - loss: 0.1348 - accuracy: 0.9701 - get_f1: 0.9701\n",
            "test accuracy is:  [0.13484889268875122, 0.970105767250061, 0.9701003432273865]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions7= model7.predict(x_test)\n",
        "\n",
        "predictions7=np.argmax(predictions7, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions7))\n",
        "cm = confusion_matrix(y_test, predictions7)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions7))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions7))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZKbWha5eCfX",
        "outputId": "a7c3563f-7388-413f-8bc4-c0aaf143e3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.916\n",
            "The confusion matric is: [[5210   92]\n",
            " [ 103 1118]]\n",
            "Accuracy: 0.970\n",
            "F1 Score: 0.920\n",
            "Precision: 0.924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRHiugubgTHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 9: 1 GRU - BiLSTM / flatten\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model8.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model8.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wl_lLBhgTJu",
        "outputId": "77179966-e4cd-407e-a295-4b3f39bfb619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 19s 20ms/step - loss: 0.4752 - accuracy: 0.8228 - get_f1: 0.8228\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4032 - accuracy: 0.8273 - get_f1: 0.8272\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.3441 - accuracy: 0.8531 - get_f1: 0.8531\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.3157 - accuracy: 0.8698 - get_f1: 0.8698\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2925 - accuracy: 0.8817 - get_f1: 0.8817\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2717 - accuracy: 0.8924 - get_f1: 0.8924\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2501 - accuracy: 0.9030 - get_f1: 0.9030\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2320 - accuracy: 0.9126 - get_f1: 0.9126\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.2156 - accuracy: 0.9199 - get_f1: 0.9200\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 9s 15ms/step - loss: 0.2024 - accuracy: 0.9255 - get_f1: 0.9255\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8d518bad90>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy8= model8.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt93YkLkgU-Y",
        "outputId": "9fc3e2f2-b830-426d-ea3c-e3b375a0364b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 9s 7ms/step - loss: 0.2303 - accuracy: 0.9169 - get_f1: 0.9170\n",
            "test accuracy is:  [0.2302737683057785, 0.916909396648407, 0.9169730544090271]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions8= model8.predict(x_test)\n",
        "\n",
        "predictions8=np.argmax(predictions8, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions8))\n",
        "cm = confusion_matrix(y_test, predictions8)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions8))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions8))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfyYksuTgVBA",
        "outputId": "c8d33f24-a401-4563-b786-2f435c0017ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.702\n",
            "The confusion matric is: [[5158  192]\n",
            " [ 350  823]]\n",
            "Accuracy: 0.917\n",
            "F1 Score: 0.752\n",
            "Precision: 0.811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zfyTZ_jO_MD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU - BiLSTM, Nadam(1e-4)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model26 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model26.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Nadam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model26.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy26= model26.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy26)\n",
        "\n",
        "predictions26= model26.predict(x_test)\n",
        "\n",
        "predictions26=np.argmax(predictions26, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions26))\n",
        "cm = confusion_matrix(y_test, predictions26)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions26))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions26))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions26))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H282XtcB_MF-",
        "outputId": "445f39f9-d2c8-4332-b99e-e7e657086e3f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 27s 25ms/step - loss: 0.4759 - accuracy: 0.8209 - get_f1: 0.8209\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.3244 - accuracy: 0.8614 - get_f1: 0.8613\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.1836 - accuracy: 0.9306 - get_f1: 0.9307\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.1157 - accuracy: 0.9592 - get_f1: 0.9592\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0797 - accuracy: 0.9739 - get_f1: 0.9740\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0575 - accuracy: 0.9816 - get_f1: 0.9816\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 16s 27ms/step - loss: 0.0444 - accuracy: 0.9867 - get_f1: 0.9867\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0372 - accuracy: 0.9884 - get_f1: 0.9884\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0320 - accuracy: 0.9900 - get_f1: 0.9900\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 13s 20ms/step - loss: 0.0294 - accuracy: 0.9903 - get_f1: 0.9903\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4527 - accuracy: 0.9056 - get_f1: 0.9056\n",
            "test accuracy is:  [0.4526790976524353, 0.9055649042129517, 0.9056088328361511]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.697\n",
            "The confusion matrix is [[5090  261]\n",
            " [ 355  817]]\n",
            "Accuracy: 0.906\n",
            "F1 Score: 0.726\n",
            "Precision: 0.758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "fj5XtN-d_faq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU - BiLSTM, Adagrad(1e-4)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model27 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model27.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adagrad(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model27.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy27= model27.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy27)\n",
        "\n",
        "predictions27= model27.predict(x_test)\n",
        "\n",
        "predictions27=np.argmax(predictions27, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions27))\n",
        "cm = confusion_matrix(y_test, predictions27)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions27))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions27))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions27))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQP8LZUr_fcg",
        "outputId": "77301342-20bc-452d-d7c2-f7b5240d8cf6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 11s 12ms/step - loss: 0.6854 - accuracy: 0.7880 - get_f1: 0.7880\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6765 - accuracy: 0.8193 - get_f1: 0.8194\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6696 - accuracy: 0.8194 - get_f1: 0.8195\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 10s 16ms/step - loss: 0.6632 - accuracy: 0.8194 - get_f1: 0.8192\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.6571 - accuracy: 0.8194 - get_f1: 0.8194\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.6512 - accuracy: 0.8194 - get_f1: 0.8193\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 9s 15ms/step - loss: 0.6455 - accuracy: 0.8194 - get_f1: 0.8195\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6402 - accuracy: 0.8194 - get_f1: 0.8194\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6343 - accuracy: 0.8194 - get_f1: 0.8194\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6282 - accuracy: 0.8194 - get_f1: 0.8195\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.6235 - accuracy: 0.8257 - get_f1: 0.8257\n",
            "test accuracy is:  [0.6235305666923523, 0.8256937265396118, 0.8257420063018799]\n",
            "204/204 [==============================] - 2s 7ms/step\n",
            "Recall: 0.000\n",
            "The confusion matrix is [[5386    0]\n",
            " [1137    0]]\n",
            "Accuracy: 0.826\n",
            "F1 Score: 0.000\n",
            "Precision: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "vhBXHqnc_smX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU - BiLSTM, Adadelta(1e-4)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model28 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model28.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adadelta(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model28.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy28= model28.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy28)\n",
        "\n",
        "predictions28= model28.predict(x_test)\n",
        "\n",
        "predictions28=np.argmax(predictions28, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions28))\n",
        "cm = confusion_matrix(y_test, predictions28)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions28))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions28))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mv3KhY6_tbi",
        "outputId": "5018c3aa-f275-439f-a0e9-74e915fef105"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 12s 12ms/step - loss: 0.6957 - accuracy: 0.2690 - get_f1: 0.2690\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6951 - accuracy: 0.3111 - get_f1: 0.3111\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6944 - accuracy: 0.3655 - get_f1: 0.3656\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6938 - accuracy: 0.4256 - get_f1: 0.4257\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6931 - accuracy: 0.5058 - get_f1: 0.5058\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 8s 14ms/step - loss: 0.6925 - accuracy: 0.5791 - get_f1: 0.5792\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6918 - accuracy: 0.6517 - get_f1: 0.6518\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 8s 12ms/step - loss: 0.6911 - accuracy: 0.7053 - get_f1: 0.7054\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6905 - accuracy: 0.7509 - get_f1: 0.7508\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.6899 - accuracy: 0.7760 - get_f1: 0.7759\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.6895 - accuracy: 0.8269 - get_f1: 0.8269\n",
            "test accuracy is:  [0.6895096898078918, 0.8269201517105103, 0.8268823623657227]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.000\n",
            "The confusion matrix is [[5394    0]\n",
            " [1129    0]]\n",
            "Accuracy: 0.827\n",
            "F1 Score: 0.000\n",
            "Precision: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "Sm4CZZbQ_tec"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU - BiLSTM, Adamax(1e-4)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model29 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model29.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adamax(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model29.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy29= model29.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy29)\n",
        "\n",
        "predictions29= model29.predict(x_test)\n",
        "\n",
        "predictions29=np.argmax(predictions29, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions29))\n",
        "cm = confusion_matrix(y_test, predictions29)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions29))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions29))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions29))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgc7zPIK_-Em",
        "outputId": "86cb31d1-5b85-48fa-b41f-c6fe68bac2d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 12s 12ms/step - loss: 0.5063 - accuracy: 0.8198 - get_f1: 0.8198\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 8s 12ms/step - loss: 0.4658 - accuracy: 0.8206 - get_f1: 0.8206\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 8s 12ms/step - loss: 0.4598 - accuracy: 0.8206 - get_f1: 0.8205\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 8s 12ms/step - loss: 0.4513 - accuracy: 0.8206 - get_f1: 0.8206\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 8s 12ms/step - loss: 0.4386 - accuracy: 0.8206 - get_f1: 0.8206\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 8s 12ms/step - loss: 0.4165 - accuracy: 0.8231 - get_f1: 0.8230\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 8s 12ms/step - loss: 0.3852 - accuracy: 0.8299 - get_f1: 0.8299\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 8s 13ms/step - loss: 0.3561 - accuracy: 0.8419 - get_f1: 0.8419\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 9s 14ms/step - loss: 0.3346 - accuracy: 0.8511 - get_f1: 0.8511\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 7s 12ms/step - loss: 0.3132 - accuracy: 0.8622 - get_f1: 0.8622\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.3707 - accuracy: 0.8389 - get_f1: 0.8389\n",
            "test accuracy is:  [0.3706783056259155, 0.83887779712677, 0.8389443755149841]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.356\n",
            "The confusion matrix is [[5059  305]\n",
            " [ 746  413]]\n",
            "Accuracy: 0.839\n",
            "F1 Score: 0.440\n",
            "Precision: 0.575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Function Tuning "
      ],
      "metadata": {
        "id": "ti6Ls2TbsAl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM , Adam 1e-4, (Softplus + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model13 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='softplus'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model13.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model13.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy13= model13.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy13)\n",
        "\n",
        "predictions13= model13.predict(x_test)\n",
        "\n",
        "predictions13=np.argmax(predictions13, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions13)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions13))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions13))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions13))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDnfntIvsDvq",
        "outputId": "67bf2454-d263-439c-eb56-3820e0cc281d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 21s 18ms/step - loss: 0.5295 - accuracy: 0.7895 - get_f1: 0.7896\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.3146 - accuracy: 0.8731 - get_f1: 0.8731\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.1653 - accuracy: 0.9432 - get_f1: 0.9432\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.0992 - accuracy: 0.9679 - get_f1: 0.9679\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.0647 - accuracy: 0.9816 - get_f1: 0.9816\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0485 - accuracy: 0.9864 - get_f1: 0.9864\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0385 - accuracy: 0.9893 - get_f1: 0.9893\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0328 - accuracy: 0.9911 - get_f1: 0.9911\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0288 - accuracy: 0.9915 - get_f1: 0.9915\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.0275 - accuracy: 0.9923 - get_f1: 0.9923\n",
            "204/204 [==============================] - 2s 7ms/step - loss: 0.4560 - accuracy: 0.8971 - get_f1: 0.8971\n",
            "test accuracy is:  [0.4560321569442749, 0.8971332311630249, 0.8971269130706787]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The confusion matrix is [[5016  316]\n",
            " [ 355  836]]\n",
            "Accuracy: 0.897\n",
            "Recall: 0.702\n",
            "Precision: 0.726\n",
            "F1 Score: 0.714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM , Adam 1e-4, (softsign + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model14 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='softsign'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model14.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model14.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy14= model14.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy14)\n",
        "\n",
        "predictions14= model14.predict(x_test)\n",
        "\n",
        "predictions14=np.argmax(predictions14, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions14)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions14))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions14))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions14))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCYYj1letlq2",
        "outputId": "7c672b72-fd50-4e20-b020-c86de049763f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 16s 19ms/step - loss: 0.4659 - accuracy: 0.8168 - get_f1: 0.8169\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.2591 - accuracy: 0.8946 - get_f1: 0.8946\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1319 - accuracy: 0.9523 - get_f1: 0.9523\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0767 - accuracy: 0.9755 - get_f1: 0.9755\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0526 - accuracy: 0.9844 - get_f1: 0.9844\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.0399 - accuracy: 0.9878 - get_f1: 0.9878\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 18s 30ms/step - loss: 0.0309 - accuracy: 0.9910 - get_f1: 0.9910\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 14s 24ms/step - loss: 0.0304 - accuracy: 0.9912 - get_f1: 0.9912\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.0264 - accuracy: 0.9919 - get_f1: 0.9919\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0245 - accuracy: 0.9925 - get_f1: 0.9925\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4904 - accuracy: 0.9033 - get_f1: 0.9033\n",
            "test accuracy is:  [0.49037274718284607, 0.9032653570175171, 0.9033111333847046]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The confusion matrix is [[5130  257]\n",
            " [ 374  762]]\n",
            "Accuracy: 0.903\n",
            "Recall: 0.671\n",
            "Precision: 0.748\n",
            "F1 Score: 0.707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM , Adam 1e-4, (tanh + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model15 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='tanh'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model15.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model15.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy15= model15.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy15)\n",
        "\n",
        "predictions15= model15.predict(x_test)\n",
        "\n",
        "predictions15=np.argmax(predictions15, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions15)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions15))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions15))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions15))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XRxkYU-uLWy",
        "outputId": "8c517abf-4ed5-4b2c-caf9-4ff4feea66a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 15s 18ms/step - loss: 0.4627 - accuracy: 0.8165 - get_f1: 0.8165\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.2556 - accuracy: 0.8947 - get_f1: 0.8948\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.1271 - accuracy: 0.9539 - get_f1: 0.9539\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0712 - accuracy: 0.9764 - get_f1: 0.9764\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 16s 25ms/step - loss: 0.0451 - accuracy: 0.9859 - get_f1: 0.9860\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.0349 - accuracy: 0.9892 - get_f1: 0.9892\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.0274 - accuracy: 0.9914 - get_f1: 0.9914\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0248 - accuracy: 0.9926 - get_f1: 0.9926\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0239 - accuracy: 0.9925 - get_f1: 0.9925\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0213 - accuracy: 0.9930 - get_f1: 0.9930\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.5449 - accuracy: 0.8968 - get_f1: 0.8968\n",
            "test accuracy is:  [0.5449200868606567, 0.8968266248703003, 0.8968204259872437]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The confusion matrix is [[5054  288]\n",
            " [ 385  796]]\n",
            "Accuracy: 0.897\n",
            "Recall: 0.674\n",
            "Precision: 0.734\n",
            "F1 Score: 0.703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM , Adam 1e-4, (selu + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model16 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='selu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model16.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model16.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy16= model16.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy16)\n",
        "\n",
        "predictions16= model16.predict(x_test)\n",
        "\n",
        "predictions16=np.argmax(predictions16, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions16)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions16))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions16))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions16))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvQaeVq-un_i",
        "outputId": "102ae5e2-9c5a-4800-9e18-ac7326f00d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 15s 18ms/step - loss: 0.4542 - accuracy: 0.8213 - get_f1: 0.8212\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.2462 - accuracy: 0.8997 - get_f1: 0.8997\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1240 - accuracy: 0.9554 - get_f1: 0.9554\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0668 - accuracy: 0.9771 - get_f1: 0.9770\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0420 - accuracy: 0.9871 - get_f1: 0.9871\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0323 - accuracy: 0.9899 - get_f1: 0.9899\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0278 - accuracy: 0.9909 - get_f1: 0.9909\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0251 - accuracy: 0.9922 - get_f1: 0.9922\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0235 - accuracy: 0.9924 - get_f1: 0.9924\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0208 - accuracy: 0.9934 - get_f1: 0.9934\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4916 - accuracy: 0.8962 - get_f1: 0.8962\n",
            "test accuracy is:  [0.4915602207183838, 0.8962134122848511, 0.8962077498435974]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The confusion matrix is [[5002  348]\n",
            " [ 329  844]]\n",
            "Accuracy: 0.896\n",
            "Recall: 0.720\n",
            "Precision: 0.708\n",
            "F1 Score: 0.714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM , Adam 1e-4, (elu + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model17 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='elu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model17.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model17.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy17= model17.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy17)\n",
        "\n",
        "predictions17= model17.predict(x_test)\n",
        "\n",
        "predictions17=np.argmax(predictions17, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions17)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions17))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions17))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions17))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions17))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M923_2p-uyaP",
        "outputId": "704c4af1-3f92-4e00-bfa8-d01333bb5d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 17s 21ms/step - loss: 0.4625 - accuracy: 0.8187 - get_f1: 0.8187\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.2591 - accuracy: 0.8933 - get_f1: 0.8933\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.1326 - accuracy: 0.9508 - get_f1: 0.9508\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0749 - accuracy: 0.9745 - get_f1: 0.9745\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0492 - accuracy: 0.9841 - get_f1: 0.9841\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0355 - accuracy: 0.9892 - get_f1: 0.9892\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0314 - accuracy: 0.9908 - get_f1: 0.9908\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0263 - accuracy: 0.9917 - get_f1: 0.9917\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0252 - accuracy: 0.9921 - get_f1: 0.9921\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0224 - accuracy: 0.9920 - get_f1: 0.9920\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.4909 - accuracy: 0.8982 - get_f1: 0.8982\n",
            "test accuracy is:  [0.4909292459487915, 0.898206353187561, 0.8981707692146301]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The confusion matrix is [[5033  367]\n",
            " [ 297  826]]\n",
            "Accuracy: 0.898\n",
            "Recall: 0.736\n",
            "Precision: 0.692\n",
            "F1 Score: 0.713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU - BiLSTM , Adam 1e-4, (exponential + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model18 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='exponential'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model18.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy',get_f1])\n",
        "\n",
        "model18.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy18= model18.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy18)\n",
        "\n",
        "predictions18= model18.predict(x_test)\n",
        "\n",
        "predictions18=np.argmax(predictions18, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions18)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions18))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions18))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions18))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions18))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0rIY0pvvMAU",
        "outputId": "0bb9afc6-0e6c-4543-da27-5c28c92b956a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 17s 18ms/step - loss: 0.6184 - accuracy: 0.7641 - get_f1: 0.7641\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.3534 - accuracy: 0.8640 - get_f1: 0.8640\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1749 - accuracy: 0.9367 - get_f1: 0.9368\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.1002 - accuracy: 0.9676 - get_f1: 0.9676\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0652 - accuracy: 0.9800 - get_f1: 0.9800\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0470 - accuracy: 0.9869 - get_f1: 0.9869\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0384 - accuracy: 0.9891 - get_f1: 0.9891\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0323 - accuracy: 0.9900 - get_f1: 0.9900\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0312 - accuracy: 0.9913 - get_f1: 0.9913\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0267 - accuracy: 0.9921 - get_f1: 0.9921\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 0.5184 - accuracy: 0.8971 - get_f1: 0.8972\n",
            "test accuracy is:  [0.5183523893356323, 0.8971332311630249, 0.8971551656723022]\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The confusion matrix is [[5023  325]\n",
            " [ 346  829]]\n",
            "Accuracy: 0.897\n",
            "Recall: 0.706\n",
            "Precision: 0.718\n",
            "F1 Score: 0.712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFMcJ_-PwfhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNInfbee_5Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Size Tuning"
      ],
      "metadata": {
        "id": "tf0OSbNTvxBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer, Batch Size (10)\n",
        "from tensorflow.keras import layers\n",
        "model19 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model19.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model19.fit(x_train, y_train, batch_size=10, epochs=10)\n",
        "\n",
        "predictions19= model19.predict(x_test)\n",
        "\n",
        "predictions19=np.argmax(predictions19, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions19))\n",
        "cm = confusion_matrix(y_test, predictions19)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions19))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions19))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions19))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ChcsdXWv4o3",
        "outputId": "9262bb93-db59-42bc-9286-ac4cc811e399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1958/1958 [==============================] - 43s 17ms/step - loss: 0.4212 - accuracy: 0.8298\n",
            "Epoch 2/10\n",
            "1958/1958 [==============================] - 33s 17ms/step - loss: 0.2187 - accuracy: 0.9150\n",
            "Epoch 3/10\n",
            "1958/1958 [==============================] - 34s 17ms/step - loss: 0.1165 - accuracy: 0.9610\n",
            "Epoch 4/10\n",
            "1958/1958 [==============================] - 34s 17ms/step - loss: 0.0704 - accuracy: 0.9773\n",
            "Epoch 5/10\n",
            "1958/1958 [==============================] - 34s 17ms/step - loss: 0.0470 - accuracy: 0.9859\n",
            "Epoch 6/10\n",
            "1958/1958 [==============================] - 34s 17ms/step - loss: 0.0383 - accuracy: 0.9885\n",
            "Epoch 7/10\n",
            "1958/1958 [==============================] - 34s 17ms/step - loss: 0.0314 - accuracy: 0.9915\n",
            "Epoch 8/10\n",
            "1958/1958 [==============================] - 34s 18ms/step - loss: 0.0279 - accuracy: 0.9915\n",
            "Epoch 9/10\n",
            "1958/1958 [==============================] - 33s 17ms/step - loss: 0.0235 - accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "1958/1958 [==============================] - 36s 18ms/step - loss: 0.0217 - accuracy: 0.9926\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.701\n",
            "The Confusion Matrix is [[5085  255]\n",
            " [ 354  829]]\n",
            "Accuracy: 0.907\n",
            "F1 Score: 0.731\n",
            "Precision: 0.765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "idWfPRGm5hOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer, Batch Size (40)\n",
        "from tensorflow.keras import layers\n",
        "model20 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model20.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model20.fit(x_train, y_train, batch_size=40, epochs=10)\n",
        "\n",
        "predictions20= model20.predict(x_test)\n",
        "\n",
        "predictions20=np.argmax(predictions20, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions20))\n",
        "cm = confusion_matrix(y_test, predictions20)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions20))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions20))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions20))"
      ],
      "metadata": {
        "id": "-afR4-w_xMkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeaf3416-cc52-48fe-cc4c-d684b98cafcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "490/490 [==============================] - 19s 23ms/step - loss: 0.4815 - accuracy: 0.8174\n",
            "Epoch 2/10\n",
            "490/490 [==============================] - 9s 18ms/step - loss: 0.2920 - accuracy: 0.8789\n",
            "Epoch 3/10\n",
            "490/490 [==============================] - 9s 17ms/step - loss: 0.1516 - accuracy: 0.9474\n",
            "Epoch 4/10\n",
            "490/490 [==============================] - 8s 17ms/step - loss: 0.0898 - accuracy: 0.9706\n",
            "Epoch 5/10\n",
            "490/490 [==============================] - 8s 17ms/step - loss: 0.0583 - accuracy: 0.9829\n",
            "Epoch 6/10\n",
            "490/490 [==============================] - 8s 17ms/step - loss: 0.0421 - accuracy: 0.9877\n",
            "Epoch 7/10\n",
            "490/490 [==============================] - 8s 17ms/step - loss: 0.0345 - accuracy: 0.9897\n",
            "Epoch 8/10\n",
            "490/490 [==============================] - 8s 17ms/step - loss: 0.0299 - accuracy: 0.9917\n",
            "Epoch 9/10\n",
            "490/490 [==============================] - 8s 17ms/step - loss: 0.0273 - accuracy: 0.9921\n",
            "Epoch 10/10\n",
            "490/490 [==============================] - 8s 17ms/step - loss: 0.0259 - accuracy: 0.9926\n",
            "204/204 [==============================] - 2s 7ms/step\n",
            "Recall: 0.681\n",
            "The Confusion Matrix is [[5094  270]\n",
            " [ 370  789]]\n",
            "Accuracy: 0.902\n",
            "F1 Score: 0.711\n",
            "Precision: 0.745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer, Batch Size (60)\n",
        "from tensorflow.keras import layers\n",
        "model21 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model21.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model21.fit(x_train, y_train, batch_size=60, epochs=10)\n",
        "\n",
        "predictions21= model21.predict(x_test)\n",
        "\n",
        "predictions21=np.argmax(predictions21, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions21))\n",
        "cm = confusion_matrix(y_test, predictions21)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions21))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions21))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions21))"
      ],
      "metadata": {
        "id": "d9pV5hL9xMmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec6fb8d-877e-49be-a789-725475127c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327/327 [==============================] - 15s 25ms/step - loss: 0.4978 - accuracy: 0.8187\n",
            "Epoch 2/10\n",
            "327/327 [==============================] - 8s 23ms/step - loss: 0.3457 - accuracy: 0.8531\n",
            "Epoch 3/10\n",
            "327/327 [==============================] - 8s 24ms/step - loss: 0.1757 - accuracy: 0.9349\n",
            "Epoch 4/10\n",
            "327/327 [==============================] - 6s 17ms/step - loss: 0.1020 - accuracy: 0.9662\n",
            "Epoch 5/10\n",
            "327/327 [==============================] - 6s 17ms/step - loss: 0.0650 - accuracy: 0.9804\n",
            "Epoch 6/10\n",
            "327/327 [==============================] - 6s 17ms/step - loss: 0.0462 - accuracy: 0.9860\n",
            "Epoch 7/10\n",
            "327/327 [==============================] - 6s 17ms/step - loss: 0.0378 - accuracy: 0.9891\n",
            "Epoch 8/10\n",
            "327/327 [==============================] - 6s 17ms/step - loss: 0.0321 - accuracy: 0.9912\n",
            "Epoch 9/10\n",
            "327/327 [==============================] - 6s 17ms/step - loss: 0.0289 - accuracy: 0.9916\n",
            "Epoch 10/10\n",
            "327/327 [==============================] - 6s 17ms/step - loss: 0.0270 - accuracy: 0.9920\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.663\n",
            "The Confusion Matrix is [[5090  272]\n",
            " [ 391  770]]\n",
            "Accuracy: 0.898\n",
            "F1 Score: 0.699\n",
            "Precision: 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer, Batch Size (80)\n",
        "from tensorflow.keras import layers\n",
        "model22 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model22.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model22.fit(x_train, y_train, batch_size=80, epochs=10)\n",
        "\n",
        "predictions22= model22.predict(x_test)\n",
        "\n",
        "predictions22=np.argmax(predictions22, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions22))\n",
        "cm = confusion_matrix(y_test, predictions22)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions22))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions22))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions22))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psdLTzjr9Q3q",
        "outputId": "0392ebb0-0597-42b2-a830-8b5736951026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245/245 [==============================] - 10s 21ms/step - loss: 0.5074 - accuracy: 0.8190\n",
            "Epoch 2/10\n",
            "245/245 [==============================] - 5s 22ms/step - loss: 0.3849 - accuracy: 0.8343\n",
            "Epoch 3/10\n",
            "245/245 [==============================] - 5s 22ms/step - loss: 0.2096 - accuracy: 0.9194\n",
            "Epoch 4/10\n",
            "245/245 [==============================] - 6s 24ms/step - loss: 0.1190 - accuracy: 0.9593\n",
            "Epoch 5/10\n",
            "245/245 [==============================] - 4s 18ms/step - loss: 0.0749 - accuracy: 0.9757\n",
            "Epoch 6/10\n",
            "245/245 [==============================] - 5s 18ms/step - loss: 0.0520 - accuracy: 0.9840\n",
            "Epoch 7/10\n",
            "245/245 [==============================] - 4s 18ms/step - loss: 0.0399 - accuracy: 0.9878\n",
            "Epoch 8/10\n",
            "245/245 [==============================] - 4s 18ms/step - loss: 0.0330 - accuracy: 0.9901\n",
            "Epoch 9/10\n",
            "245/245 [==============================] - 4s 18ms/step - loss: 0.0292 - accuracy: 0.9912\n",
            "Epoch 10/10\n",
            "245/245 [==============================] - 4s 18ms/step - loss: 0.0253 - accuracy: 0.9919\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "Recall: 0.698\n",
            "The Confusion Matrix is [[5048  305]\n",
            " [ 353  817]]\n",
            "Accuracy: 0.899\n",
            "F1 Score: 0.713\n",
            "Precision: 0.728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epochs Tuning"
      ],
      "metadata": {
        "id": "0ATWYNlJv71-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer, Batch Size (32), Epochs(25)\n",
        "from tensorflow.keras import layers\n",
        "model23 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model23.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model23.fit(x_train, y_train, batch_size=32, epochs=25)\n",
        "\n",
        "predictions23= model23.predict(x_test)\n",
        "\n",
        "predictions23=np.argmax(predictions23, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions23)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions23))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions23))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions23))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions23))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgw8Yxlx96GE",
        "outputId": "0c9e8a17-adaf-482a-9027-240703900ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 18s 20ms/step - loss: 0.4754 - accuracy: 0.8216\n",
            "Epoch 2/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.2930 - accuracy: 0.8791\n",
            "Epoch 3/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.1507 - accuracy: 0.9471\n",
            "Epoch 4/25\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.0871 - accuracy: 0.9727\n",
            "Epoch 5/25\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0588 - accuracy: 0.9823\n",
            "Epoch 6/25\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0417 - accuracy: 0.9875\n",
            "Epoch 7/25\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0344 - accuracy: 0.9901\n",
            "Epoch 8/25\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.0296 - accuracy: 0.9911\n",
            "Epoch 9/25\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0260 - accuracy: 0.9927\n",
            "Epoch 10/25\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.0240 - accuracy: 0.9928\n",
            "Epoch 11/25\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0238 - accuracy: 0.9933\n",
            "Epoch 12/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0223 - accuracy: 0.9931\n",
            "Epoch 13/25\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0205 - accuracy: 0.9930\n",
            "Epoch 14/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0205 - accuracy: 0.9929\n",
            "Epoch 15/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0195 - accuracy: 0.9930\n",
            "Epoch 16/25\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0180 - accuracy: 0.9935\n",
            "Epoch 17/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0177 - accuracy: 0.9940\n",
            "Epoch 18/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0161 - accuracy: 0.9938\n",
            "Epoch 19/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0162 - accuracy: 0.9936\n",
            "Epoch 20/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0157 - accuracy: 0.9937\n",
            "Epoch 21/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0153 - accuracy: 0.9935\n",
            "Epoch 22/25\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0146 - accuracy: 0.9936\n",
            "Epoch 23/25\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0139 - accuracy: 0.9935\n",
            "Epoch 24/25\n",
            "612/612 [==============================] - 10s 16ms/step - loss: 0.0126 - accuracy: 0.9942\n",
            "Epoch 25/25\n",
            "612/612 [==============================] - 10s 16ms/step - loss: 0.0124 - accuracy: 0.9940\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The Confusion Matrix is [[4968  358]\n",
            " [ 355  842]]\n",
            "Accuracy: 0.891\n",
            "Recall: 0.703\n",
            "Precision: 0.702\n",
            "F1 Score: 0.703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "dzUecFO3-LQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer, Batch Size (32), Epochs(50)\n",
        "from tensorflow.keras import layers\n",
        "model24 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model24.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model24.fit(x_train, y_train, batch_size=32, epochs=50)\n",
        "\n",
        "predictions24= model24.predict(x_test)\n",
        "\n",
        "predictions24=np.argmax(predictions24, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions24)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions24))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions24))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions24))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions24))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkaDcMZH-NOd",
        "outputId": "f3dfed7a-bf23-4686-e42a-cfc4383cace8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 14s 17ms/step - loss: 0.4783 - accuracy: 0.8164\n",
            "Epoch 2/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.2788 - accuracy: 0.8891\n",
            "Epoch 3/50\n",
            "612/612 [==============================] - 10s 16ms/step - loss: 0.1431 - accuracy: 0.9497\n",
            "Epoch 4/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0813 - accuracy: 0.9747\n",
            "Epoch 5/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0533 - accuracy: 0.9845\n",
            "Epoch 6/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0392 - accuracy: 0.9894\n",
            "Epoch 7/50\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0329 - accuracy: 0.9913\n",
            "Epoch 8/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0296 - accuracy: 0.9917\n",
            "Epoch 9/50\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0280 - accuracy: 0.9925\n",
            "Epoch 10/50\n",
            "612/612 [==============================] - 10s 16ms/step - loss: 0.0247 - accuracy: 0.9923\n",
            "Epoch 11/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0242 - accuracy: 0.9927\n",
            "Epoch 12/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0214 - accuracy: 0.9935\n",
            "Epoch 13/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0207 - accuracy: 0.9934\n",
            "Epoch 14/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0188 - accuracy: 0.9937\n",
            "Epoch 15/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0184 - accuracy: 0.9937\n",
            "Epoch 16/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0171 - accuracy: 0.9934\n",
            "Epoch 17/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0162 - accuracy: 0.9933\n",
            "Epoch 18/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0159 - accuracy: 0.9937\n",
            "Epoch 19/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0149 - accuracy: 0.9937\n",
            "Epoch 20/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0142 - accuracy: 0.9935\n",
            "Epoch 21/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0136 - accuracy: 0.9941\n",
            "Epoch 22/50\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0134 - accuracy: 0.9937\n",
            "Epoch 23/50\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0117 - accuracy: 0.9946\n",
            "Epoch 24/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0125 - accuracy: 0.9943\n",
            "Epoch 25/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0116 - accuracy: 0.9941\n",
            "Epoch 26/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0108 - accuracy: 0.9945\n",
            "Epoch 27/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0111 - accuracy: 0.9950\n",
            "Epoch 28/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0100 - accuracy: 0.9944\n",
            "Epoch 29/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0105 - accuracy: 0.9942\n",
            "Epoch 30/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0098 - accuracy: 0.9944\n",
            "Epoch 31/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0101 - accuracy: 0.9955\n",
            "Epoch 32/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0098 - accuracy: 0.9946\n",
            "Epoch 33/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0100 - accuracy: 0.9950\n",
            "Epoch 34/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0097 - accuracy: 0.9948\n",
            "Epoch 35/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0096 - accuracy: 0.9947\n",
            "Epoch 36/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0090 - accuracy: 0.9945\n",
            "Epoch 37/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0087 - accuracy: 0.9955\n",
            "Epoch 38/50\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0091 - accuracy: 0.9953\n",
            "Epoch 39/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0099 - accuracy: 0.9950\n",
            "Epoch 40/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0085 - accuracy: 0.9958\n",
            "Epoch 41/50\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0085 - accuracy: 0.9952\n",
            "Epoch 42/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0091 - accuracy: 0.9953\n",
            "Epoch 43/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0090 - accuracy: 0.9948\n",
            "Epoch 44/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0086 - accuracy: 0.9954\n",
            "Epoch 45/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0086 - accuracy: 0.9952\n",
            "Epoch 46/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0084 - accuracy: 0.9951\n",
            "Epoch 47/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0082 - accuracy: 0.9953\n",
            "Epoch 48/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0085 - accuracy: 0.9949\n",
            "Epoch 49/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0089 - accuracy: 0.9949\n",
            "Epoch 50/50\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0081 - accuracy: 0.9949\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The Confusion Matrix is [[5077  306]\n",
            " [ 353  787]]\n",
            "Accuracy: 0.899\n",
            "Recall: 0.690\n",
            "Precision: 0.720\n",
            "F1 Score: 0.705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "K3ixOXHK-NQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU layer followed by BiLSTM layer, Batch Size (32), Epochs(75)\n",
        "from tensorflow.keras import layers\n",
        "model25 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model25.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model25.fit(x_train, y_train, batch_size=32, epochs=75)\n",
        "\n",
        "predictions25= model25.predict(x_test)\n",
        "\n",
        "predictions25=np.argmax(predictions25, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions25)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions25))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions25))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions25))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWzk25pd-qGW",
        "outputId": "fe76aa36-94a2-4e04-b382-91e10dd78e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 14s 17ms/step - loss: 0.4728 - accuracy: 0.8193\n",
            "Epoch 2/75\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.2736 - accuracy: 0.8871\n",
            "Epoch 3/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.1405 - accuracy: 0.9500\n",
            "Epoch 4/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0815 - accuracy: 0.9722\n",
            "Epoch 5/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0538 - accuracy: 0.9838\n",
            "Epoch 6/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0401 - accuracy: 0.9889\n",
            "Epoch 7/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0338 - accuracy: 0.9903\n",
            "Epoch 8/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0288 - accuracy: 0.9922\n",
            "Epoch 9/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0274 - accuracy: 0.9919\n",
            "Epoch 10/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0241 - accuracy: 0.9935\n",
            "Epoch 11/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0241 - accuracy: 0.9924\n",
            "Epoch 12/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0211 - accuracy: 0.9934\n",
            "Epoch 13/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0221 - accuracy: 0.9929\n",
            "Epoch 14/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0199 - accuracy: 0.9930\n",
            "Epoch 15/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0174 - accuracy: 0.9938\n",
            "Epoch 16/75\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.0176 - accuracy: 0.9937\n",
            "Epoch 17/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0163 - accuracy: 0.9932\n",
            "Epoch 18/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0161 - accuracy: 0.9930\n",
            "Epoch 19/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0148 - accuracy: 0.9932\n",
            "Epoch 20/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0143 - accuracy: 0.9934\n",
            "Epoch 21/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0135 - accuracy: 0.9940\n",
            "Epoch 22/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0140 - accuracy: 0.9937\n",
            "Epoch 23/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0129 - accuracy: 0.9936\n",
            "Epoch 24/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0124 - accuracy: 0.9936\n",
            "Epoch 25/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0110 - accuracy: 0.9943\n",
            "Epoch 26/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0115 - accuracy: 0.9939\n",
            "Epoch 27/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0111 - accuracy: 0.9936\n",
            "Epoch 28/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0105 - accuracy: 0.9936\n",
            "Epoch 29/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0101 - accuracy: 0.9942\n",
            "Epoch 30/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0099 - accuracy: 0.9941\n",
            "Epoch 31/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0099 - accuracy: 0.9944\n",
            "Epoch 32/75\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0092 - accuracy: 0.9943\n",
            "Epoch 33/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0093 - accuracy: 0.9950\n",
            "Epoch 34/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0086 - accuracy: 0.9948\n",
            "Epoch 35/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0089 - accuracy: 0.9945\n",
            "Epoch 36/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0084 - accuracy: 0.9951\n",
            "Epoch 37/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0085 - accuracy: 0.9949\n",
            "Epoch 38/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0091 - accuracy: 0.9945\n",
            "Epoch 39/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0089 - accuracy: 0.9950\n",
            "Epoch 40/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0090 - accuracy: 0.9948\n",
            "Epoch 41/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0082 - accuracy: 0.9949\n",
            "Epoch 42/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0082 - accuracy: 0.9953\n",
            "Epoch 43/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0082 - accuracy: 0.9949\n",
            "Epoch 44/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0081 - accuracy: 0.9955\n",
            "Epoch 45/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0082 - accuracy: 0.9948\n",
            "Epoch 46/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0081 - accuracy: 0.9949\n",
            "Epoch 47/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0081 - accuracy: 0.9948\n",
            "Epoch 48/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0082 - accuracy: 0.9943\n",
            "Epoch 49/75\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0091 - accuracy: 0.9950\n",
            "Epoch 50/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0082 - accuracy: 0.9949\n",
            "Epoch 51/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0080 - accuracy: 0.9954\n",
            "Epoch 52/75\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0088 - accuracy: 0.9948\n",
            "Epoch 53/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0079 - accuracy: 0.9949\n",
            "Epoch 54/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0079 - accuracy: 0.9948\n",
            "Epoch 55/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0079 - accuracy: 0.9952\n",
            "Epoch 56/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0084 - accuracy: 0.9946\n",
            "Epoch 57/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0088 - accuracy: 0.9949\n",
            "Epoch 58/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0078 - accuracy: 0.9956\n",
            "Epoch 59/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0079 - accuracy: 0.9956\n",
            "Epoch 60/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0079 - accuracy: 0.9951\n",
            "Epoch 61/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0079 - accuracy: 0.9952\n",
            "Epoch 62/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0077 - accuracy: 0.9949\n",
            "Epoch 63/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0078 - accuracy: 0.9952\n",
            "Epoch 64/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0078 - accuracy: 0.9954\n",
            "Epoch 65/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0079 - accuracy: 0.9951\n",
            "Epoch 66/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0078 - accuracy: 0.9948\n",
            "Epoch 67/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0077 - accuracy: 0.9956\n",
            "Epoch 68/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0077 - accuracy: 0.9954\n",
            "Epoch 69/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0083 - accuracy: 0.9954\n",
            "Epoch 70/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0076 - accuracy: 0.9950\n",
            "Epoch 71/75\n",
            "612/612 [==============================] - 10s 17ms/step - loss: 0.0078 - accuracy: 0.9954\n",
            "Epoch 72/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0078 - accuracy: 0.9951\n",
            "Epoch 73/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0077 - accuracy: 0.9950\n",
            "Epoch 74/75\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0078 - accuracy: 0.9954\n",
            "Epoch 75/75\n",
            "612/612 [==============================] - 11s 17ms/step - loss: 0.0077 - accuracy: 0.9952\n",
            "204/204 [==============================] - 2s 5ms/step\n",
            "The Confusion Matrix is [[5010  351]\n",
            " [ 335  827]]\n",
            "Accuracy: 0.895\n",
            "Recall: 0.712\n",
            "Precision: 0.702\n",
            "F1 Score: 0.707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNdbC4Lj-9Eu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}