{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "__PYCbUTQC49",
        "peDsnXnxRYDE",
        "onGsVEOPT8DP",
        "f2PkrEu-e-gy",
        "Z7ThpOk0kzV6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f25083d37cc148aa998fc2b87bb4714c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cff98cbd2a3c4951a67e1a14d6e72690",
              "IPY_MODEL_6e3f974617144684a3d5d0d9081a53c3",
              "IPY_MODEL_18c2672060644337a66ff612adbdceac"
            ],
            "layout": "IPY_MODEL_d53633d132e24b85bf9656bf4a1bb506"
          }
        },
        "cff98cbd2a3c4951a67e1a14d6e72690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db1cc00a43f444ae92be5c9fa1162ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_da36ba4436ef4c9a99ea31d2019eedcc",
            "value": "Downloading: 100%"
          }
        },
        "6e3f974617144684a3d5d0d9081a53c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67e17fa934143849013d126595c587b",
            "max": 379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d160dd0636947c1960d1f87f8fa55a1",
            "value": 379
          }
        },
        "18c2672060644337a66ff612adbdceac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8944873d971a49288866556a5802354b",
            "placeholder": "​",
            "style": "IPY_MODEL_f6de615cc2994b3087d9c970fae6d846",
            "value": " 379/379 [00:00&lt;00:00, 17.4kB/s]"
          }
        },
        "d53633d132e24b85bf9656bf4a1bb506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1cc00a43f444ae92be5c9fa1162ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da36ba4436ef4c9a99ea31d2019eedcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e67e17fa934143849013d126595c587b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d160dd0636947c1960d1f87f8fa55a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8944873d971a49288866556a5802354b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6de615cc2994b3087d9c970fae6d846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1338c764ff59454a8636869197723ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89b9b810c9234278b5bc6c96d999d660",
              "IPY_MODEL_dd408899649949789d2ea4f55313bac9",
              "IPY_MODEL_7ac4b5a188454a88aefc119e111ceab4"
            ],
            "layout": "IPY_MODEL_83fe3394a4b84d1aab9175e8b4fe7acd"
          }
        },
        "89b9b810c9234278b5bc6c96d999d660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f011033e1a42468e88cfb9fc02a8f0",
            "placeholder": "​",
            "style": "IPY_MODEL_2fb617685b114a5e8e50a472f398af5b",
            "value": "Downloading: 100%"
          }
        },
        "dd408899649949789d2ea4f55313bac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a40abb57f61a48bda16816f35bd8cded",
            "max": 576,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e03033e6017c420f9d58056a1e662a86",
            "value": 576
          }
        },
        "7ac4b5a188454a88aefc119e111ceab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f92a7f4f02d45e3a929bded3a839c42",
            "placeholder": "​",
            "style": "IPY_MODEL_ae73637dd7cb4e9495d555b90a4489f7",
            "value": " 576/576 [00:00&lt;00:00, 17.4kB/s]"
          }
        },
        "83fe3394a4b84d1aab9175e8b4fe7acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f011033e1a42468e88cfb9fc02a8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb617685b114a5e8e50a472f398af5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a40abb57f61a48bda16816f35bd8cded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03033e6017c420f9d58056a1e662a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f92a7f4f02d45e3a929bded3a839c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae73637dd7cb4e9495d555b90a4489f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ca7be6b805c47468daf566e50865737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9eaf8faaefb42958a6c476c60719256",
              "IPY_MODEL_40f055bbc8e94247a495f81ac5b07928",
              "IPY_MODEL_7e7115bd86004ae88675739a1ccd85e2"
            ],
            "layout": "IPY_MODEL_953791baf02d410599c680f15cd74fb9"
          }
        },
        "f9eaf8faaefb42958a6c476c60719256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb3110bfd2bc412ab2b8969c372ad6c8",
            "placeholder": "​",
            "style": "IPY_MODEL_ee88105be18c40678decb4f8d697612a",
            "value": "Downloading: 100%"
          }
        },
        "40f055bbc8e94247a495f81ac5b07928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e4742c1c390424e94dc8c251af4a914",
            "max": 780034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45c6f421a8dd407192d249a0dfc47c52",
            "value": 780034
          }
        },
        "7e7115bd86004ae88675739a1ccd85e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ccfb6b154a4fd489a7ee79a91f57de",
            "placeholder": "​",
            "style": "IPY_MODEL_68aaf4b487124fb6b5e7e0332bc3fe28",
            "value": " 780k/780k [00:00&lt;00:00, 6.29MB/s]"
          }
        },
        "953791baf02d410599c680f15cd74fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3110bfd2bc412ab2b8969c372ad6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee88105be18c40678decb4f8d697612a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e4742c1c390424e94dc8c251af4a914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c6f421a8dd407192d249a0dfc47c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23ccfb6b154a4fd489a7ee79a91f57de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68aaf4b487124fb6b5e7e0332bc3fe28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54822a3b3fd24389905ac13b9692ea95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e59472de781547bfa835745943a96afc",
              "IPY_MODEL_2a4496bc95a7443789276cc3d74dbcca",
              "IPY_MODEL_a05cf37394324dbd9cc05c509dd0fbeb"
            ],
            "layout": "IPY_MODEL_c1ff76c0f9d7471d9fa654806f0a38b2"
          }
        },
        "e59472de781547bfa835745943a96afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c326f87bff3e47bda2d2d6b3a4ee82df",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d1440193fd4d8e9e11dfb4e212f9dd",
            "value": "Downloading: 100%"
          }
        },
        "2a4496bc95a7443789276cc3d74dbcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a644d291e38c45db88d614f56d78bfc9",
            "max": 2697421,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f531369945904eab99029f2a177272bc",
            "value": 2697421
          }
        },
        "a05cf37394324dbd9cc05c509dd0fbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ca155fd0464d1caffadea41f094529",
            "placeholder": "​",
            "style": "IPY_MODEL_69da351d8cf54a818ce335c06621c0ac",
            "value": " 2.70M/2.70M [00:00&lt;00:00, 7.15MB/s]"
          }
        },
        "c1ff76c0f9d7471d9fa654806f0a38b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c326f87bff3e47bda2d2d6b3a4ee82df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d1440193fd4d8e9e11dfb4e212f9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a644d291e38c45db88d614f56d78bfc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f531369945904eab99029f2a177272bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6ca155fd0464d1caffadea41f094529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69da351d8cf54a818ce335c06621c0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c1408de12364eb2ae3ce106de29bfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_824e664a78724dc79e8b1a1316fc2294",
              "IPY_MODEL_74006be540264925b497c7607623960b",
              "IPY_MODEL_59f55cf14cb6492f802a0fa5318d64db"
            ],
            "layout": "IPY_MODEL_b5613003e1dd4123908398b423dbbcfa"
          }
        },
        "824e664a78724dc79e8b1a1316fc2294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b8f5bac83e432cb0e5968259fde76b",
            "placeholder": "​",
            "style": "IPY_MODEL_68611d1f6eee4426a7dcc2e53f6b82b9",
            "value": "Downloading: 100%"
          }
        },
        "74006be540264925b497c7607623960b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e69337d0e11407aa3ddca220b2f504d",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7485a2b843349e1ac3bedf9706d3ccf",
            "value": 112
          }
        },
        "59f55cf14cb6492f802a0fa5318d64db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b42fd668fb497eb906d8931033db8b",
            "placeholder": "​",
            "style": "IPY_MODEL_cbcb211cb8c141bd8132fc7dc281cbee",
            "value": " 112/112 [00:00&lt;00:00, 5.56kB/s]"
          }
        },
        "b5613003e1dd4123908398b423dbbcfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b8f5bac83e432cb0e5968259fde76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68611d1f6eee4426a7dcc2e53f6b82b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e69337d0e11407aa3ddca220b2f504d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7485a2b843349e1ac3bedf9706d3ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64b42fd668fb497eb906d8931033db8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcb211cb8c141bd8132fc7dc281cbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "!pip install gensim spacy nltk\n",
        "import re \n",
        "import gensim\n",
        "import spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzQhCxHnQz9s",
        "outputId": "6e5ce5db-248f-4766-e4c2-8bde586502a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dek5aCWdNAM8",
        "outputId": "1f096680-1da2-4251-99d7-8584db662087"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('/content/drive/My Drive/Cleaned Data/Sarcasm.csv') "
      ],
      "metadata": {
        "id": "Lmo4neG-OfsV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "max_sequence_length = np.max(data['Number of Words in tweet'])\n",
        "print(\"max length is:\", max_sequence_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeYcAwqjOhPh",
        "outputId": "d38eadb2-a6ee-432d-edb9-2d36fd2ca696"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length is: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = data['cleaned_tweet']\n",
        "label = data['sarcasm']"
      ],
      "metadata": {
        "id": "CbbKvvYxOiKo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=30000)\n",
        "tokenizer.fit_on_texts(text.astype(str))\n",
        "sequences = tokenizer.texts_to_sequences(text.astype(str))\n",
        "\n",
        "word_index = tokenizer.word_index   # a dictionary of each word and its index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "print('Shape of data tensor:', data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bu_FkO8OjTa",
        "outputId": "541b4eef-6fb3-4e6d-e3fa-92e822cd593d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 55395 unique tokens.\n",
            "Shape of data tensor: (26095, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "labels = to_categorical(np.asarray(label))  ## one hot of the output\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3emOVuXOqwy",
        "outputId": "aaeee2cb-ccc8-462c-b243-6303bb6fc4af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (26095, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "i1IEF0VpO4GH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arabert"
      ],
      "metadata": {
        "id": "__PYCbUTQC49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install pyarabic\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T9dar5-QFlV",
        "outputId": "47b4f0e5-24e6-4c77-defe-812a095fd68d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=4899dab07aff01d38813a7252b0c45ac23b210afdaebcf9060422cb8355d3f45\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a4/72/df07592cea3ae06b5e846f5e52262f8b16748e829ca354b7df\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=ea01aafe5fd768d452f927503244a8bc23b45b7fb2042ad3bdc49469fea462e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f3/85/b8cf1d8bfe55dc2ece0f1fcd4e91d6f8fc7b59ff3fd75329e1\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=680c9f26cd743643113a550166ae07cf22fbc376eb83d1b5400d73a0e3904bf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/26/e9/df16869ccbd4abf517f1ff3be9a2c7ee5c5980fc87eea04fb1\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 600, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (600/600), 9.14 MiB | 32.28 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HPB_5gUGQK8Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoemK47uQPkJ",
        "outputId": "9603c9ba-1c66-4fc6-f51c-eba927cab146"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arabert_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv01\",do_lower_case=False)\n",
        "def encode_sentence(sent):\n",
        "    tokenized = arabert_tokenizer.tokenize(sent)\n",
        "    return arabert_tokenizer.convert_tokens_to_ids(tokenized)"
      ],
      "metadata": {
        "id": "nXHxjYL6QRIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "f25083d37cc148aa998fc2b87bb4714c",
            "cff98cbd2a3c4951a67e1a14d6e72690",
            "6e3f974617144684a3d5d0d9081a53c3",
            "18c2672060644337a66ff612adbdceac",
            "d53633d132e24b85bf9656bf4a1bb506",
            "db1cc00a43f444ae92be5c9fa1162ba9",
            "da36ba4436ef4c9a99ea31d2019eedcc",
            "e67e17fa934143849013d126595c587b",
            "4d160dd0636947c1960d1f87f8fa55a1",
            "8944873d971a49288866556a5802354b",
            "f6de615cc2994b3087d9c970fae6d846",
            "1338c764ff59454a8636869197723ad9",
            "89b9b810c9234278b5bc6c96d999d660",
            "dd408899649949789d2ea4f55313bac9",
            "7ac4b5a188454a88aefc119e111ceab4",
            "83fe3394a4b84d1aab9175e8b4fe7acd",
            "d8f011033e1a42468e88cfb9fc02a8f0",
            "2fb617685b114a5e8e50a472f398af5b",
            "a40abb57f61a48bda16816f35bd8cded",
            "e03033e6017c420f9d58056a1e662a86",
            "0f92a7f4f02d45e3a929bded3a839c42",
            "ae73637dd7cb4e9495d555b90a4489f7",
            "4ca7be6b805c47468daf566e50865737",
            "f9eaf8faaefb42958a6c476c60719256",
            "40f055bbc8e94247a495f81ac5b07928",
            "7e7115bd86004ae88675739a1ccd85e2",
            "953791baf02d410599c680f15cd74fb9",
            "bb3110bfd2bc412ab2b8969c372ad6c8",
            "ee88105be18c40678decb4f8d697612a",
            "8e4742c1c390424e94dc8c251af4a914",
            "45c6f421a8dd407192d249a0dfc47c52",
            "23ccfb6b154a4fd489a7ee79a91f57de",
            "68aaf4b487124fb6b5e7e0332bc3fe28",
            "54822a3b3fd24389905ac13b9692ea95",
            "e59472de781547bfa835745943a96afc",
            "2a4496bc95a7443789276cc3d74dbcca",
            "a05cf37394324dbd9cc05c509dd0fbeb",
            "c1ff76c0f9d7471d9fa654806f0a38b2",
            "c326f87bff3e47bda2d2d6b3a4ee82df",
            "f8d1440193fd4d8e9e11dfb4e212f9dd",
            "a644d291e38c45db88d614f56d78bfc9",
            "f531369945904eab99029f2a177272bc",
            "d6ca155fd0464d1caffadea41f094529",
            "69da351d8cf54a818ce335c06621c0ac",
            "7c1408de12364eb2ae3ce106de29bfd0",
            "824e664a78724dc79e8b1a1316fc2294",
            "74006be540264925b497c7607623960b",
            "59f55cf14cb6492f802a0fa5318d64db",
            "b5613003e1dd4123908398b423dbbcfa",
            "b8b8f5bac83e432cb0e5968259fde76b",
            "68611d1f6eee4426a7dcc2e53f6b82b9",
            "7e69337d0e11407aa3ddca220b2f504d",
            "c7485a2b843349e1ac3bedf9706d3ccf",
            "64b42fd668fb497eb906d8931033db8b",
            "cbcb211cb8c141bd8132fc7dc281cbee"
          ]
        },
        "outputId": "893f4447-ce30-45bf-9cb9-de6a24e3825a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/379 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f25083d37cc148aa998fc2b87bb4714c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/576 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1338c764ff59454a8636869197723ad9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ca7be6b805c47468daf566e50865737"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.70M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54822a3b3fd24389905ac13b9692ea95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c1408de12364eb2ae3ce106de29bfd0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200"
      ],
      "metadata": {
        "id": "KtdtQlpjQScU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkbBhnWxRXRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM-BiLSTM Models"
      ],
      "metadata": {
        "id": "peDsnXnxRYDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BiLSTM Layers with Adam(1e-4), (Relu + Sigmoid)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "predictions= model.predict(x_test)\n",
        "predictions=np.argmax(predictions, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU-gucpvRazT",
        "outputId": "2c657bec-a954-442d-ad53-df19a7c32efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 22s 25ms/step - loss: 0.4485 - accuracy: 0.8245\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.2558 - accuracy: 0.8998\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 16s 27ms/step - loss: 0.1346 - accuracy: 0.9540\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0774 - accuracy: 0.9755\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0519 - accuracy: 0.9854\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 18s 30ms/step - loss: 0.0381 - accuracy: 0.9897\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0314 - accuracy: 0.9904\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0260 - accuracy: 0.9915\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0230 - accuracy: 0.9922\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0210 - accuracy: 0.9930\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The Confusion Matrix is [[5092  233]\n",
            " [ 370  828]]\n",
            "Accuracy: 0.908\n",
            "Recall: 0.691\n",
            "Precision: 0.780\n",
            "F1 Score: 0.733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BiLSTM Layers, Adam(1e-4), (Relu+Softmax)\n",
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy1= model1.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy1)\n",
        "\n",
        "predictions1= model1.predict(x_test)\n",
        "predictions1=np.argmax(predictions1, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions1)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions1))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions1))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions1))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjAkHYNISiwI",
        "outputId": "7cc36ecc-ca15-4717-c626-fefbf8601160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 20s 24ms/step - loss: 0.4580 - accuracy: 0.8220\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.2867 - accuracy: 0.8840\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.1648 - accuracy: 0.9414\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0957 - accuracy: 0.9689\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0612 - accuracy: 0.9822\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0431 - accuracy: 0.9881\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0354 - accuracy: 0.9900\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0280 - accuracy: 0.9917\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0255 - accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 18s 30ms/step - loss: 0.0209 - accuracy: 0.9928\n",
            "204/204 [==============================] - 4s 13ms/step - loss: 0.4377 - accuracy: 0.9046\n",
            "test accuracy is:  [0.43770232796669006, 0.9046450853347778]\n",
            "204/204 [==============================] - 4s 12ms/step\n",
            "The Confusion Matrix is [[5098  289]\n",
            " [ 333  803]]\n",
            "Accuracy: 0.905\n",
            "Recall: 0.707\n",
            "Precision: 0.735\n",
            "F1 Score: 0.721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Functions Tuning"
      ],
      "metadata": {
        "id": "onGsVEOPT8DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Adam(1e-3), (softplus + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='softplus'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy2= model2.evaluate(x_test, y_test)\n",
        "print('test accuracy is: ', accuracy2)\n",
        "\n",
        "predictions2= model2.predict(x_test)\n",
        "predictions2=np.argmax(predictions2, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions2)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions2))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions2))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions2))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hswa1HG_UKWL",
        "outputId": "a5f1df03-7a61-4a58-b051-fc5047337dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 32s 37ms/step - loss: 0.4376 - accuracy: 0.8250\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 22s 35ms/step - loss: 0.2283 - accuracy: 0.9154\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 24s 39ms/step - loss: 0.1258 - accuracy: 0.9596\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 24s 40ms/step - loss: 0.0899 - accuracy: 0.9727\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 23s 38ms/step - loss: 0.0535 - accuracy: 0.9854\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 21s 35ms/step - loss: 0.0401 - accuracy: 0.9885\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 23s 38ms/step - loss: 0.0273 - accuracy: 0.9911\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 24s 39ms/step - loss: 0.0196 - accuracy: 0.9932\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 22s 37ms/step - loss: 0.0159 - accuracy: 0.9926\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 21s 35ms/step - loss: 0.0151 - accuracy: 0.9931\n",
            "204/204 [==============================] - 4s 12ms/step - loss: 0.4706 - accuracy: 0.9085\n",
            "test accuracy is:  [0.47063565254211426, 0.9084777235984802]\n",
            "204/204 [==============================] - 4s 11ms/step\n",
            "The confusion matrix is [[5111  258]\n",
            " [ 339  815]]\n",
            "Accuracy: 0.908\n",
            "Recall: 0.706\n",
            "Precision: 0.760\n",
            "F1 Score: 0.732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 BiLSTM Layers  1e-3, Adam (softsign + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='softsign'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model4.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model4.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy4= model4.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy4)\n",
        "\n",
        "predictions4= model4.predict(x_test)\n",
        "predictions4=np.argmax(predictions4, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions4)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions4))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions4))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions4))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-mtBUV3b8xj",
        "outputId": "0329fa5a-3c3a-4b1a-ad88-abf60b403cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 23s 25ms/step - loss: 0.3716 - accuracy: 0.8475\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.1443 - accuracy: 0.9497\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0529 - accuracy: 0.9842\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0266 - accuracy: 0.9908\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0175 - accuracy: 0.9917\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0144 - accuracy: 0.9927\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0126 - accuracy: 0.9932\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0119 - accuracy: 0.9935\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0165 - accuracy: 0.9924\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0150 - accuracy: 0.9929\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.4827 - accuracy: 0.9122\n",
            "test accuracy is:  [0.4826553165912628, 0.9121569991111755]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The confusion matrix is [[5149  242]\n",
            " [ 331  801]]\n",
            "Accuracy: 0.912\n",
            "Recall: 0.708\n",
            "Precision: 0.768\n",
            "F1 Score: 0.204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 BiLSTM Layers  1e-3, Adam (tanh + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='tanh'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model5.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model5.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy5= model5.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy5)\n",
        "\n",
        "predictions5= model5.predict(x_test)\n",
        "predictions5=np.argmax(predictions5, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions5)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions5))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions5))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions5))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHUKoJkocV61",
        "outputId": "a589dbad-065d-4bf5-a9e3-205bf0d1c1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 21s 25ms/step - loss: 0.3632 - accuracy: 0.8489\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.1305 - accuracy: 0.9543\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0422 - accuracy: 0.9857\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0210 - accuracy: 0.9909\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 16s 25ms/step - loss: 0.0183 - accuracy: 0.9910\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.0176 - accuracy: 0.9921\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0133 - accuracy: 0.9926\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0147 - accuracy: 0.9926\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0127 - accuracy: 0.9935\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0128 - accuracy: 0.9931\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.6222 - accuracy: 0.8996\n",
            "test accuracy is:  [0.6221893429756165, 0.8995860815048218]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The confusion matrix is [[5048  284]\n",
            " [ 371  820]]\n",
            "Accuracy: 0.900\n",
            "Recall: 0.688\n",
            "Precision: 0.743\n",
            "F1 Score: 0.715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 BiLSTM Layers, Adam(1e-3), (selu + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='selu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model6.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model6.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy5= model6.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy5)\n",
        "predictions6= model6.predict(x_test)\n",
        "predictions6=np.argmax(predictions6, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions6)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions6))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions6))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions6))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions6))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HNff-GqcfD6",
        "outputId": "98f16267-3deb-4159-c61e-4cd0ee477a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 20s 24ms/step - loss: 0.3674 - accuracy: 0.8512\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.1346 - accuracy: 0.9504\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0457 - accuracy: 0.9857\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0211 - accuracy: 0.9913\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0150 - accuracy: 0.9925\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0138 - accuracy: 0.9923\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0135 - accuracy: 0.9924\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0134 - accuracy: 0.9931\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0146 - accuracy: 0.9924\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0115 - accuracy: 0.9939\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.6118 - accuracy: 0.9020\n",
            "test accuracy is:  [0.6117690801620483, 0.9020389318466187]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The confusion matrix is [[5109  232]\n",
            " [ 407  775]]\n",
            "Accuracy: 0.902\n",
            "Recall: 0.656\n",
            "Precision: 0.770\n",
            "F1 Score: 0.708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 BiLSTM Layers  1e-3, Adam (elu + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='elu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model7.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model7.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "accuracy7= model7.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy7)\n",
        "\n",
        "predictions7= model7.predict(x_test)\n",
        "predictions7=np.argmax(predictions7, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions7)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions7))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions7))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions7))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions7))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElCEGKXocfGQ",
        "outputId": "05b5574a-8b1c-496a-c46b-38a7bff09736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 22s 27ms/step - loss: 0.3662 - accuracy: 0.8503\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.1353 - accuracy: 0.9508\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0451 - accuracy: 0.9852\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0224 - accuracy: 0.9909\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0154 - accuracy: 0.9924\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0140 - accuracy: 0.9929\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0132 - accuracy: 0.9931\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0120 - accuracy: 0.9937\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0120 - accuracy: 0.9930\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0167 - accuracy: 0.9918\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.6903 - accuracy: 0.8954\n",
            "test accuracy is:  [0.6903421878814697, 0.8954468965530396]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The confusion matrix is [[4979  371]\n",
            " [ 311  862]]\n",
            "Accuracy: 0.895\n",
            "Recall: 0.735\n",
            "Precision: 0.699\n",
            "F1 Score: 0.717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 BiLSTM Layers  1e-3, Adam (exponential + softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='exponential'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model8.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model8.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy8= model8.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy8)\n",
        "\n",
        "\n",
        "predictions8= model8.predict(x_test)\n",
        "predictions8=np.argmax(predictions8, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions8)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions8))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions8))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions8))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions8))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjRd_Gp-cfIp",
        "outputId": "65615698-7d3d-4e0b-b32e-3643ef6da4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 20s 24ms/step - loss: 0.4508 - accuracy: 0.8250\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.2354 - accuracy: 0.9140\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.1213 - accuracy: 0.9606\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0634 - accuracy: 0.9804\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0345 - accuracy: 0.9879\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0223 - accuracy: 0.9907\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0199 - accuracy: 0.9921\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0166 - accuracy: 0.9927\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0133 - accuracy: 0.9937\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0129 - accuracy: 0.9935\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.8908 - accuracy: 0.9048\n",
            "test accuracy is:  [0.8907906413078308, 0.9047983884811401]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The confusion matrix is [[5027  297]\n",
            " [ 324  875]]\n",
            "Accuracy: 0.905\n",
            "Recall: 0.730\n",
            "Precision: 0.747\n",
            "F1 Score: 0.738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate & Optimizers Hyperparameter Tuning on (Relu + Softmax)"
      ],
      "metadata": {
        "id": "U_SlaFybh4Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Adam(1e-3), (Relu + Softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model3.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy3= model3.evaluate(x_test, y_test)\n",
        "print('test accuracy is: ', accuracy3)\n",
        "\n",
        "predictions3= model3.predict(x_test)\n",
        "predictions3=np.argmax(predictions3, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions3)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions3))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions3))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions3))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIdgj8kLT-Bf",
        "outputId": "4a361ee5-fc8b-4328-be4b-7aaef6b9f4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 20s 25ms/step - loss: 0.4091 - accuracy: 0.8234\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.2369 - accuracy: 0.9011\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.1741 - accuracy: 0.9298\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0919 - accuracy: 0.9647\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.0440 - accuracy: 0.9848\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0229 - accuracy: 0.9915\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0180 - accuracy: 0.9924\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 20s 33ms/step - loss: 0.0136 - accuracy: 0.9936\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0129 - accuracy: 0.9942\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0120 - accuracy: 0.9931\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.7381 - accuracy: 0.9023\n",
            "test accuracy is:  [0.7381117939949036, 0.9023455381393433]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The Confusion Matrix is [[5074  264]\n",
            " [ 373  812]]\n",
            "Accuracy: 0.902\n",
            "Recall: 0.685\n",
            "Precision: 0.755\n",
            "F1 Score: 0.718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Adam(1e-2), (Relu+Softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model9 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model9.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-2),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model9.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy9= model9.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy9)\n",
        "\n",
        "\n",
        "predictions9= model9.predict(x_test)\n",
        "predictions9=np.argmax(predictions9, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions9)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions9))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions9))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions9))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6iP5ZITcfKs",
        "outputId": "73af5914-82f8-4a57-a5ac-c5e4d6114db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 20s 24ms/step - loss: 0.4496 - accuracy: 0.8215\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.3407 - accuracy: 0.8758\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.3255 - accuracy: 0.8815\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.3236 - accuracy: 0.8912\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 17s 27ms/step - loss: 0.3540 - accuracy: 0.8688\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 18s 29ms/step - loss: 0.3322 - accuracy: 0.8713\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.3159 - accuracy: 0.8733\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.2909 - accuracy: 0.8813\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.2757 - accuracy: 0.8831\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.2579 - accuracy: 0.8905\n",
            "204/204 [==============================] - 6s 15ms/step - loss: 0.4225 - accuracy: 0.8456\n",
            "test accuracy is:  [0.4225436747074127, 0.8456231951713562]\n",
            "204/204 [==============================] - 4s 11ms/step\n",
            "The confusion matrix is [[5112  213]\n",
            " [ 794  404]]\n",
            "Accuracy: 0.846\n",
            "Recall: 0.337\n",
            "Precision: 0.655\n",
            "F1 Score: 0.445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Adam(1e-1), (Relu+Softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model10 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model10.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model10.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy10= model10.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy10)\n",
        "\n",
        "predictions10= model10.predict(x_test)\n",
        "predictions10=np.argmax(predictions10, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions10))\n",
        "cm = confusion_matrix(y_test, predictions10)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions10))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions10))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhY97Xr-dZzj",
        "outputId": "a347b6ef-3d94-489d-e907-cca61d6397aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 21s 24ms/step - loss: 0.4927 - accuracy: 0.8158\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 18s 29ms/step - loss: 0.4748 - accuracy: 0.8188\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.4747 - accuracy: 0.8188\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.4752 - accuracy: 0.8188\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.4747 - accuracy: 0.8188\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.4747 - accuracy: 0.8188\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.4744 - accuracy: 0.8188\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.4750 - accuracy: 0.8188\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.4747 - accuracy: 0.8188\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.4746 - accuracy: 0.8188\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.4636 - accuracy: 0.8277\n",
            "test accuracy is:  [0.4636305570602417, 0.8276866674423218]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "Recall: 0.000\n",
            "The confusion matrix is [[5399    0]\n",
            " [1124    0]]\n",
            "Accuracy: 0.828\n",
            "F1 Score: 0.000\n",
            "Precision: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers with Softmax loss function at the dense layer, 1e-4, RMSprop\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model11 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model11.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model11.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy11= model11.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy11)\n",
        "\n",
        "predictions11= model11.predict(x_test)\n",
        "predictions11=np.argmax(predictions11, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions11))\n",
        "cm = confusion_matrix(y_test, predictions11)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions11))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions11))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions11))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UtWCSl4enhZ",
        "outputId": "e18f7782-029b-4f5a-f405-15125ca740f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 25s 30ms/step - loss: 0.4633 - accuracy: 0.8209\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 19s 31ms/step - loss: 0.3737 - accuracy: 0.8436\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 19s 31ms/step - loss: 0.3278 - accuracy: 0.8653\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.2983 - accuracy: 0.8802\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 19s 31ms/step - loss: 0.2748 - accuracy: 0.8911\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.2536 - accuracy: 0.9016\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.2327 - accuracy: 0.9098\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 13s 20ms/step - loss: 0.2138 - accuracy: 0.9193\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 17s 29ms/step - loss: 0.1944 - accuracy: 0.9275\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.1756 - accuracy: 0.9355\n",
            "204/204 [==============================] - 7s 14ms/step - loss: 0.3580 - accuracy: 0.8735\n",
            "test accuracy is:  [0.3579888343811035, 0.8735244274139404]\n",
            "204/204 [==============================] - 6s 14ms/step\n",
            "Recall: 0.515\n",
            "The confusion matrix is [[5093  256]\n",
            " [ 569  605]]\n",
            "Accuracy: 0.874\n",
            "F1 Score: 0.595\n",
            "Precision: 0.703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "AxApgUfHe4Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers with Softmax loss function at the dense layer, 1e-3, RMSprop\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model12 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model12.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model12.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy12= model12.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy12)\n",
        "\n",
        "predictions12= model12.predict(x_test)\n",
        "predictions12=np.argmax(predictions12, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions12))\n",
        "cm = confusion_matrix(y_test, predictions12)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions12))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions12))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL33pl6Venm9",
        "outputId": "a22cff89-3f2e-401a-c32d-ac870cf50b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 30s 31ms/step - loss: 0.4128 - accuracy: 0.8318\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 19s 30ms/step - loss: 0.2490 - accuracy: 0.9062\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.1541 - accuracy: 0.9447\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 19s 31ms/step - loss: 0.0998 - accuracy: 0.9648\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 20s 33ms/step - loss: 0.0705 - accuracy: 0.9769\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 18s 30ms/step - loss: 0.0537 - accuracy: 0.9836\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 17s 29ms/step - loss: 0.0409 - accuracy: 0.9869\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 19s 31ms/step - loss: 0.0323 - accuracy: 0.9900\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0271 - accuracy: 0.9911\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0246 - accuracy: 0.9926\n",
            "204/204 [==============================] - 4s 12ms/step - loss: 0.7195 - accuracy: 0.8587\n",
            "test accuracy is:  [0.7195138335227966, 0.8586540222167969]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "Recall: 0.796\n",
            "The confusion matrix is [[4666  683]\n",
            " [ 239  935]]\n",
            "Accuracy: 0.859\n",
            "F1 Score: 0.670\n",
            "Precision: 0.578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "Dzd4HXFie51W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers with Softmax loss function at the dense layer, 1e-2, RMSprop\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model13 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model13.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-2),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model13.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy13= model13.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy13)\n",
        "\n",
        "predictions13= model13.predict(x_test)\n",
        "predictions13=np.argmax(predictions13, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions13))\n",
        "cm = confusion_matrix(y_test, predictions13)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions13))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions13))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVXgA2b7enpZ",
        "outputId": "9008edd8-e223-4410-db5d-84f2f7bb83f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 21s 20ms/step - loss: 0.4564 - accuracy: 0.8200\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.3393 - accuracy: 0.8788\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.2360 - accuracy: 0.9220\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.1788 - accuracy: 0.9438\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.1465 - accuracy: 0.9579\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.1224 - accuracy: 0.9632\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 14s 24ms/step - loss: 0.1126 - accuracy: 0.9694\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.0997 - accuracy: 0.9733\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 18s 29ms/step - loss: 0.0926 - accuracy: 0.9751\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.0871 - accuracy: 0.9779\n",
            "204/204 [==============================] - 5s 11ms/step - loss: 0.6114 - accuracy: 0.8984\n",
            "test accuracy is:  [0.611417293548584, 0.8983596563339233]\n",
            "204/204 [==============================] - 4s 10ms/step\n",
            "Recall: 0.646\n",
            "The confusion matrix is [[5104  249]\n",
            " [ 414  756]]\n",
            "Accuracy: 0.898\n",
            "F1 Score: 0.695\n",
            "Precision: 0.752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "D0Abyo7Ae9EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers with Softmax loss function at the dense layer, 1e-1, RMSprop\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model14 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model14.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(1e-1),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model14.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy14= model14.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy14)\n",
        "\n",
        "predictions14= model14.predict(x_test)\n",
        "predictions14=np.argmax(predictions14, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions14))\n",
        "cm = confusion_matrix(y_test, predictions14)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions14))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions14))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxGwd_i6ensA",
        "outputId": "ae705680-d8bf-41e5-bd08-acee47e3d86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 25s 30ms/step - loss: 0.7577 - accuracy: 0.8094\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 16s 27ms/step - loss: 0.5525 - accuracy: 0.8186\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 17s 28ms/step - loss: 0.6187 - accuracy: 0.8106\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.5502 - accuracy: 0.8211\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.5761 - accuracy: 0.8179\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.6016 - accuracy: 0.8165\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.5756 - accuracy: 0.8212\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.5903 - accuracy: 0.8203\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.5814 - accuracy: 0.8192\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 12s 20ms/step - loss: 0.5401 - accuracy: 0.8214\n",
            "204/204 [==============================] - 5s 12ms/step - loss: 0.4968 - accuracy: 0.8108\n",
            "test accuracy is:  [0.4967586398124695, 0.8108232617378235]\n",
            "204/204 [==============================] - 4s 11ms/step\n",
            "Recall: 0.000\n",
            "The confusion matrix is [[5289    4]\n",
            " [1230    0]]\n",
            "Accuracy: 0.811\n",
            "F1 Score: 0.000\n",
            "Precision: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "trbLM582enu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Nadam(1e-3), (Relu + Softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model22 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model22.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Nadam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model22.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy22= model22.evaluate(x_test, y_test)\n",
        "print('test accuracy is: ', accuracy22)\n",
        "\n",
        "predictions22= model22.predict(x_test)\n",
        "predictions22=np.argmax(predictions22, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions22)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions22))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions22))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions22))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions22))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzp2W2yjsX6F",
        "outputId": "84c7fcf3-7450-4086-e938-9a40e98e86a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 26s 25ms/step - loss: 0.3877 - accuracy: 0.8409\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.1644 - accuracy: 0.9431\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0605 - accuracy: 0.9815\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0269 - accuracy: 0.9898\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0177 - accuracy: 0.9909\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0144 - accuracy: 0.9933\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 16s 26ms/step - loss: 0.0211 - accuracy: 0.9901\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0122 - accuracy: 0.9928\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0110 - accuracy: 0.9930\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0098 - accuracy: 0.9938\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.7893 - accuracy: 0.8959\n",
            "test accuracy is:  [0.7893011569976807, 0.8959068059921265]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The Confusion Matrix is [[5057  309]\n",
            " [ 370  787]]\n",
            "Accuracy: 0.896\n",
            "Recall: 0.680\n",
            "Precision: 0.718\n",
            "F1 Score: 0.699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "FF_vIcJ1s6Up"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Adagrad(1e-3), (Relu + Softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model23 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model23.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adagrad(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model23.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy23= model23.evaluate(x_test, y_test)\n",
        "print('test accuracy is: ', accuracy23)\n",
        "\n",
        "predictions23= model23.predict(x_test)\n",
        "predictions23=np.argmax(predictions23, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions23)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions23))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions23))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions23))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions23))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN-MAStlss8P",
        "outputId": "43d36b2f-5f29-4e17-a68d-5e9a86a156f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 17s 19ms/step - loss: 0.6226 - accuracy: 0.8200\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.5061 - accuracy: 0.8236\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.4712 - accuracy: 0.8236\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4707 - accuracy: 0.8236\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4695 - accuracy: 0.8236\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4693 - accuracy: 0.8236\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4683 - accuracy: 0.8236\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4686 - accuracy: 0.8236\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4688 - accuracy: 0.8236\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.4673 - accuracy: 0.8236\n",
            "204/204 [==============================] - 3s 8ms/step - loss: 0.4782 - accuracy: 0.8131\n",
            "test accuracy is:  [0.4782329201698303, 0.8131228089332581]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The Confusion Matrix is [[5304    0]\n",
            " [1219    0]]\n",
            "Accuracy: 0.813\n",
            "Recall: 0.000\n",
            "Precision: 0.000\n",
            "F1 Score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "Ki2c1Jefs7jl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Adadelta(1e-3), (Relu + Softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model24 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model24.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adadelta(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model24.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy24= model24.evaluate(x_test, y_test)\n",
        "print('test accuracy is: ', accuracy24)\n",
        "\n",
        "predictions24= model24.predict(x_test)\n",
        "predictions24=np.argmax(predictions24, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions24)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions24))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions24))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions24))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions24))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkCk0c1Xs9MK",
        "outputId": "f80763bf-8d75-49f0-f526-67d19ee3ad97"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 17s 19ms/step - loss: 0.6918 - accuracy: 0.5858\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.6830 - accuracy: 0.8177\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.6731 - accuracy: 0.8218\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 12s 19ms/step - loss: 0.6617 - accuracy: 0.8218\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.6476 - accuracy: 0.8218\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.6308 - accuracy: 0.8218\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.6112 - accuracy: 0.8218\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.5904 - accuracy: 0.8218\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.5682 - accuracy: 0.8218\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.5484 - accuracy: 0.8218\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.5374 - accuracy: 0.8186\n",
            "test accuracy is:  [0.537430465221405, 0.818641722202301]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The Confusion Matrix is [[5340    0]\n",
            " [1183    0]]\n",
            "Accuracy: 0.819\n",
            "Recall: 0.000\n",
            "Precision: 0.000\n",
            "F1 Score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "wvoez0Sot3Jt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BiLSTM Layers, Adamax(1e-3), (Relu + Softmax)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model25 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model25.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adamax(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model25.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "\n",
        "accuracy25= model25.evaluate(x_test, y_test)\n",
        "print('test accuracy is: ', accuracy25)\n",
        "\n",
        "predictions25= model25.predict(x_test)\n",
        "predictions25=np.argmax(predictions25, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions25)\n",
        "print('The Confusion Matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions25))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions25))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions25))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXlfQjKFt4sE",
        "outputId": "dba5d516-34c6-4bf3-fa42-aa4c5a20983d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 17s 19ms/step - loss: 0.4607 - accuracy: 0.8163\n",
            "Epoch 2/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.3763 - accuracy: 0.8315\n",
            "Epoch 3/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.2952 - accuracy: 0.8780\n",
            "Epoch 4/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.2282 - accuracy: 0.9138\n",
            "Epoch 5/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.1689 - accuracy: 0.9402\n",
            "Epoch 6/10\n",
            "612/612 [==============================] - 13s 21ms/step - loss: 0.1243 - accuracy: 0.9579\n",
            "Epoch 7/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.0927 - accuracy: 0.9707\n",
            "Epoch 8/10\n",
            "612/612 [==============================] - 11s 19ms/step - loss: 0.0656 - accuracy: 0.9795\n",
            "Epoch 9/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0524 - accuracy: 0.9842\n",
            "Epoch 10/10\n",
            "612/612 [==============================] - 11s 18ms/step - loss: 0.0432 - accuracy: 0.9866\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.3694 - accuracy: 0.9148\n",
            "test accuracy is:  [0.3694216310977936, 0.9147631525993347]\n",
            "204/204 [==============================] - 3s 8ms/step\n",
            "The Confusion Matrix is [[5163  252]\n",
            " [ 304  804]]\n",
            "Accuracy: 0.915\n",
            "Recall: 0.726\n",
            "Precision: 0.761\n",
            "F1 Score: 0.743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Size Tuning"
      ],
      "metadata": {
        "id": "f2PkrEu-e-gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "eWcLmPQPfAkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers , Batch Size(10)\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model15 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model15.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model15.fit(x_train, y_train, batch_size=10, epochs=10)\n",
        "\n",
        "accuracy15= model15.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy15)\n",
        "\n",
        "predictions15= model15.predict(x_test)\n",
        "predictions15=np.argmax(predictions15, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions15)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions15))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions15))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions15))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R4bo-OCfBVs",
        "outputId": "14910a4f-730a-46ee-cc7f-6a701abb8bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1958/1958 [==============================] - 49s 21ms/step - loss: 0.3927 - accuracy: 0.8418\n",
            "Epoch 2/10\n",
            "1958/1958 [==============================] - 40s 21ms/step - loss: 0.1779 - accuracy: 0.9339\n",
            "Epoch 3/10\n",
            "1958/1958 [==============================] - 41s 21ms/step - loss: 0.0695 - accuracy: 0.9768\n",
            "Epoch 4/10\n",
            "1958/1958 [==============================] - 55s 28ms/step - loss: 0.0301 - accuracy: 0.9892\n",
            "Epoch 5/10\n",
            "1958/1958 [==============================] - 56s 28ms/step - loss: 0.0195 - accuracy: 0.9909\n",
            "Epoch 6/10\n",
            "1958/1958 [==============================] - 40s 21ms/step - loss: 0.0146 - accuracy: 0.9926\n",
            "Epoch 7/10\n",
            "1958/1958 [==============================] - 41s 21ms/step - loss: 0.0133 - accuracy: 0.9928\n",
            "Epoch 8/10\n",
            "1958/1958 [==============================] - 41s 21ms/step - loss: 0.0116 - accuracy: 0.9937\n",
            "Epoch 9/10\n",
            "1958/1958 [==============================] - 41s 21ms/step - loss: 0.0109 - accuracy: 0.9940\n",
            "Epoch 10/10\n",
            "1958/1958 [==============================] - 42s 21ms/step - loss: 0.0096 - accuracy: 0.9944\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.9169 - accuracy: 0.8982\n",
            "test accuracy is:  [0.9168974757194519, 0.898206353187561]\n",
            "204/204 [==============================] - 3s 7ms/step\n",
            "The confusion matrix is [[4989  345]\n",
            " [ 319  870]]\n",
            "Accuracy: 0.898\n",
            "Recall: 0.732\n",
            "Precision: 0.716\n",
            "F1 Score: 0.724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "Wq4plBFIgrMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers , Batch Size(40)\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model16 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model16.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model16.fit(x_train, y_train, batch_size=40, epochs=10)\n",
        "\n",
        "accuracy16= model16.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy16)\n",
        "\n",
        "predictions16= model16.predict(x_test)\n",
        "predictions16=np.argmax(predictions16, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions16)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions16))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions16))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions16))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c9l1If-gsDr",
        "outputId": "8df60d1a-f298-4945-e6ee-a4448334e21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "490/490 [==============================] - 16s 22ms/step - loss: 0.3972 - accuracy: 0.8366\n",
            "Epoch 2/10\n",
            "490/490 [==============================] - 11s 23ms/step - loss: 0.1848 - accuracy: 0.9316\n",
            "Epoch 3/10\n",
            "490/490 [==============================] - 11s 22ms/step - loss: 0.0727 - accuracy: 0.9776\n",
            "Epoch 4/10\n",
            "490/490 [==============================] - 11s 23ms/step - loss: 0.0376 - accuracy: 0.9887\n",
            "Epoch 5/10\n",
            "490/490 [==============================] - 11s 23ms/step - loss: 0.0206 - accuracy: 0.9909\n",
            "Epoch 6/10\n",
            "490/490 [==============================] - 12s 24ms/step - loss: 0.0150 - accuracy: 0.9937\n",
            "Epoch 7/10\n",
            "490/490 [==============================] - 11s 22ms/step - loss: 0.0143 - accuracy: 0.9932\n",
            "Epoch 8/10\n",
            "490/490 [==============================] - 11s 22ms/step - loss: 0.0134 - accuracy: 0.9926\n",
            "Epoch 9/10\n",
            "490/490 [==============================] - 11s 22ms/step - loss: 0.0131 - accuracy: 0.9934\n",
            "Epoch 10/10\n",
            "490/490 [==============================] - 11s 22ms/step - loss: 0.0123 - accuracy: 0.9933\n",
            "204/204 [==============================] - 4s 8ms/step - loss: 0.6663 - accuracy: 0.8936\n",
            "test accuracy is:  [0.6662517189979553, 0.8936072587966919]\n",
            "204/204 [==============================] - 3s 7ms/step\n",
            "The confusion matrix is [[5028  327]\n",
            " [ 367  801]]\n",
            "Accuracy: 0.894\n",
            "Recall: 0.686\n",
            "Precision: 0.710\n",
            "F1 Score: 0.698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "CeT7V7s0g4Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers , Batch Size(60)\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model17 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model17.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model17.fit(x_train, y_train, batch_size=60, epochs=10)\n",
        "\n",
        "accuracy17= model17.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy17)\n",
        "\n",
        "predictions17= model17.predict(x_test)\n",
        "predictions17=np.argmax(predictions17, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions17)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions17))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions17))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions17))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions17))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W22TGhWg4cH",
        "outputId": "18ea206b-c2a8-478b-8ab3-bbb85b63bcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327/327 [==============================] - 13s 24ms/step - loss: 0.3976 - accuracy: 0.8362\n",
            "Epoch 2/10\n",
            "327/327 [==============================] - 8s 23ms/step - loss: 0.1609 - accuracy: 0.9417\n",
            "Epoch 3/10\n",
            "327/327 [==============================] - 8s 23ms/step - loss: 0.0611 - accuracy: 0.9821\n",
            "Epoch 4/10\n",
            "327/327 [==============================] - 8s 24ms/step - loss: 0.0332 - accuracy: 0.9890\n",
            "Epoch 5/10\n",
            "327/327 [==============================] - 8s 24ms/step - loss: 0.0167 - accuracy: 0.9919\n",
            "Epoch 6/10\n",
            "327/327 [==============================] - 8s 24ms/step - loss: 0.0140 - accuracy: 0.9925\n",
            "Epoch 7/10\n",
            "327/327 [==============================] - 8s 24ms/step - loss: 0.0126 - accuracy: 0.9929\n",
            "Epoch 8/10\n",
            "327/327 [==============================] - 8s 24ms/step - loss: 0.0150 - accuracy: 0.9925\n",
            "Epoch 9/10\n",
            "327/327 [==============================] - 8s 24ms/step - loss: 0.0146 - accuracy: 0.9923\n",
            "Epoch 10/10\n",
            "327/327 [==============================] - 8s 23ms/step - loss: 0.0143 - accuracy: 0.9926\n",
            "204/204 [==============================] - 3s 8ms/step - loss: 0.6326 - accuracy: 0.8990\n",
            "test accuracy is:  [0.6326462626457214, 0.8989728689193726]\n",
            "204/204 [==============================] - 3s 7ms/step\n",
            "The confusion matrix is [[5050  345]\n",
            " [ 314  814]]\n",
            "Accuracy: 0.899\n",
            "Recall: 0.722\n",
            "Precision: 0.702\n",
            "F1 Score: 0.712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "c9CVPsCPhBop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers , Batch Size(80)\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model18 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model18.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model18.fit(x_train, y_train, batch_size=80, epochs=10)\n",
        "\n",
        "accuracy18= model18.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy18)\n",
        "\n",
        "predictions18= model18.predict(x_test)\n",
        "predictions18=np.argmax(predictions18, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions18)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions18))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions18))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions18))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions18))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orvdOWtIhBun",
        "outputId": "3002cdea-7619-41c0-ccff-6d96c443c086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245/245 [==============================] - 11s 26ms/step - loss: 0.4364 - accuracy: 0.8254\n",
            "Epoch 2/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.2250 - accuracy: 0.9167\n",
            "Epoch 3/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.0966 - accuracy: 0.9682\n",
            "Epoch 4/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.0483 - accuracy: 0.9861\n",
            "Epoch 5/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.0290 - accuracy: 0.9908\n",
            "Epoch 6/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.0189 - accuracy: 0.9931\n",
            "Epoch 7/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.0152 - accuracy: 0.9938\n",
            "Epoch 8/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.0184 - accuracy: 0.9916\n",
            "Epoch 9/10\n",
            "245/245 [==============================] - 6s 26ms/step - loss: 0.0133 - accuracy: 0.9932\n",
            "Epoch 10/10\n",
            "245/245 [==============================] - 7s 27ms/step - loss: 0.0116 - accuracy: 0.9936\n",
            "204/204 [==============================] - 4s 9ms/step - loss: 0.5782 - accuracy: 0.9076\n",
            "test accuracy is:  [0.5782036781311035, 0.9075578451156616]\n",
            "204/204 [==============================] - 3s 7ms/step\n",
            "The confusion matrix is [[5049  287]\n",
            " [ 316  871]]\n",
            "Accuracy: 0.908\n",
            "Recall: 0.734\n",
            "Precision: 0.752\n",
            "F1 Score: 0.743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sk61kx1RhbmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epochs Tuning "
      ],
      "metadata": {
        "id": "Z7ThpOk0kzV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "y-pTz0X5k54_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers, Epoch(25)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model19 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model19.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model19.fit(x_train, y_train, batch_size=32, epochs=25)\n",
        "\n",
        "accuracy19= model19.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy19)\n",
        "\n",
        "predictions19= model19.predict(x_test)\n",
        "predictions19=np.argmax(predictions19, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions19)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions19))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions19))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions19))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions19))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odMw4UrKk2B4",
        "outputId": "fd8a7f38-b968-46bc-bf8d-c70299d8302a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 20s 23ms/step - loss: 0.4141 - accuracy: 0.8335\n",
            "Epoch 2/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.2150 - accuracy: 0.9227\n",
            "Epoch 3/25\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.1146 - accuracy: 0.9630\n",
            "Epoch 4/25\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0613 - accuracy: 0.9814\n",
            "Epoch 5/25\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0332 - accuracy: 0.9878\n",
            "Epoch 6/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0224 - accuracy: 0.9912\n",
            "Epoch 7/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0185 - accuracy: 0.9917\n",
            "Epoch 8/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0152 - accuracy: 0.9929\n",
            "Epoch 9/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0114 - accuracy: 0.9939\n",
            "Epoch 10/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0109 - accuracy: 0.9941\n",
            "Epoch 11/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0127 - accuracy: 0.9942\n",
            "Epoch 12/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0174 - accuracy: 0.9919\n",
            "Epoch 13/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0128 - accuracy: 0.9937\n",
            "Epoch 14/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0116 - accuracy: 0.9940\n",
            "Epoch 15/25\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0100 - accuracy: 0.9947\n",
            "Epoch 16/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0088 - accuracy: 0.9946\n",
            "Epoch 17/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0088 - accuracy: 0.9948\n",
            "Epoch 18/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0107 - accuracy: 0.9947\n",
            "Epoch 19/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0160 - accuracy: 0.9932\n",
            "Epoch 20/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0118 - accuracy: 0.9942\n",
            "Epoch 21/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0088 - accuracy: 0.9946\n",
            "Epoch 22/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0085 - accuracy: 0.9950\n",
            "Epoch 23/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0087 - accuracy: 0.9950\n",
            "Epoch 24/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0084 - accuracy: 0.9947\n",
            "Epoch 25/25\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0083 - accuracy: 0.9949\n",
            "204/204 [==============================] - 3s 8ms/step - loss: 0.9128 - accuracy: 0.9007\n",
            "test accuracy is:  [0.9128445386886597, 0.9006592035293579]\n",
            "204/204 [==============================] - 3s 7ms/step\n",
            "The confusion matrix is [[5035  302]\n",
            " [ 346  840]]\n",
            "Accuracy: 0.901\n",
            "Recall: 0.708\n",
            "Precision: 0.736\n",
            "F1 Score: 0.722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "-CiI8hTvlpJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers, Epoch(50)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model20 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model20.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model20.fit(x_train, y_train, batch_size=32, epochs=50)\n",
        "\n",
        "accuracy20= model20.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy20)\n",
        "\n",
        "predictions20= model20.predict(x_test)\n",
        "predictions20=np.argmax(predictions20, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions20)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions20))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions20))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions20))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cn7NO4HlqO4",
        "outputId": "85182fbd-db72-490f-865d-bdca0d325266"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612/612 [==============================] - 19s 22ms/step - loss: 0.4322 - accuracy: 0.8297\n",
            "Epoch 2/50\n",
            "612/612 [==============================] - 14s 24ms/step - loss: 0.2285 - accuracy: 0.9137\n",
            "Epoch 3/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0980 - accuracy: 0.9686\n",
            "Epoch 4/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0461 - accuracy: 0.9855\n",
            "Epoch 5/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0237 - accuracy: 0.9908\n",
            "Epoch 6/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0164 - accuracy: 0.9926\n",
            "Epoch 7/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0123 - accuracy: 0.9925\n",
            "Epoch 8/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0107 - accuracy: 0.9935\n",
            "Epoch 9/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0137 - accuracy: 0.9923\n",
            "Epoch 10/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0158 - accuracy: 0.9928\n",
            "Epoch 11/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0122 - accuracy: 0.9934\n",
            "Epoch 12/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0109 - accuracy: 0.9936\n",
            "Epoch 13/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0097 - accuracy: 0.9940\n",
            "Epoch 14/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0099 - accuracy: 0.9942\n",
            "Epoch 15/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0106 - accuracy: 0.9937\n",
            "Epoch 16/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0091 - accuracy: 0.9936\n",
            "Epoch 17/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0117 - accuracy: 0.9935\n",
            "Epoch 18/50\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0114 - accuracy: 0.9935\n",
            "Epoch 19/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0100 - accuracy: 0.9940\n",
            "Epoch 20/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0087 - accuracy: 0.9949\n",
            "Epoch 21/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0087 - accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0087 - accuracy: 0.9946\n",
            "Epoch 23/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0090 - accuracy: 0.9949\n",
            "Epoch 24/50\n",
            "612/612 [==============================] - 13s 22ms/step - loss: 0.0092 - accuracy: 0.9943\n",
            "Epoch 25/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0091 - accuracy: 0.9950\n",
            "Epoch 26/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0086 - accuracy: 0.9947\n",
            "Epoch 27/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0086 - accuracy: 0.9947\n",
            "Epoch 28/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0086 - accuracy: 0.9948\n",
            "Epoch 29/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0086 - accuracy: 0.9950\n",
            "Epoch 30/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0084 - accuracy: 0.9946\n",
            "Epoch 31/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0087 - accuracy: 0.9947\n",
            "Epoch 32/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0112 - accuracy: 0.9940\n",
            "Epoch 33/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0110 - accuracy: 0.9942\n",
            "Epoch 34/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0095 - accuracy: 0.9947\n",
            "Epoch 35/50\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0085 - accuracy: 0.9951\n",
            "Epoch 36/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0084 - accuracy: 0.9948\n",
            "Epoch 37/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0084 - accuracy: 0.9950\n",
            "Epoch 38/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0085 - accuracy: 0.9951\n",
            "Epoch 39/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0084 - accuracy: 0.9950\n",
            "Epoch 40/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0084 - accuracy: 0.9951\n",
            "Epoch 41/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0088 - accuracy: 0.9952\n",
            "Epoch 42/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0083 - accuracy: 0.9951\n",
            "Epoch 43/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0084 - accuracy: 0.9950\n",
            "Epoch 44/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0083 - accuracy: 0.9951\n",
            "Epoch 45/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0109 - accuracy: 0.9948\n",
            "Epoch 46/50\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0085 - accuracy: 0.9949\n",
            "Epoch 47/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0090 - accuracy: 0.9951\n",
            "Epoch 48/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0099 - accuracy: 0.9948\n",
            "Epoch 49/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0086 - accuracy: 0.9950\n",
            "Epoch 50/50\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0082 - accuracy: 0.9949\n",
            "204/204 [==============================] - 3s 9ms/step - loss: 0.9238 - accuracy: 0.8984\n",
            "test accuracy is:  [0.9237842559814453, 0.8983596563339233]\n",
            "204/204 [==============================] - 3s 7ms/step\n",
            "The confusion matrix is [[5010  344]\n",
            " [ 319  850]]\n",
            "Accuracy: 0.898\n",
            "Recall: 0.727\n",
            "Precision: 0.712\n",
            "F1 Score: 0.719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #shuffle the data\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# split the data into training, testing\n",
        "\n",
        "nb_validation_samples = int(0.25* data.shape[0])\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_test = data[-nb_validation_samples:]\n",
        "y_test = labels[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "D9rwvpC6mYP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: 2 BiLSTM Layers, Epoch(75)\n",
        "\n",
        "VOCAB_SIZE = len(arabert_tokenizer.get_vocab())\n",
        "EMB_DIM = 200\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "model21 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMB_DIM,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(EMB_DIM, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model21.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model21.fit(x_train, y_train, batch_size=32, epochs=75)\n",
        "\n",
        "accuracy21= model21.evaluate(x_test, y_test)\n",
        "# print('test loss is:', loss)\n",
        "print('test accuracy is: ', accuracy21)\n",
        "\n",
        "predictions21= model21.predict(x_test)\n",
        "predictions21=np.argmax(predictions21, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions21)\n",
        "print('The confusion matrix is', cm)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, predictions21))\n",
        "print('Recall: %.3f' % recall_score(y_test, predictions21))\n",
        "print('Precision: %.3f' % precision_score(y_test, predictions21))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, predictions21))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcDHkTkymZtU",
        "outputId": "ca52d6e8-2eea-4770-ded6-789288d7e6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "612/612 [==============================] - 31s 33ms/step - loss: 0.4056 - accuracy: 0.8354\n",
            "Epoch 2/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.1841 - accuracy: 0.9349\n",
            "Epoch 3/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0724 - accuracy: 0.9786\n",
            "Epoch 4/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0319 - accuracy: 0.9887\n",
            "Epoch 5/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0182 - accuracy: 0.9918\n",
            "Epoch 6/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0137 - accuracy: 0.9930\n",
            "Epoch 7/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0112 - accuracy: 0.9939\n",
            "Epoch 8/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0092 - accuracy: 0.9941\n",
            "Epoch 9/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0088 - accuracy: 0.9944\n",
            "Epoch 10/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0080 - accuracy: 0.9950\n",
            "Epoch 11/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0115 - accuracy: 0.9931\n",
            "Epoch 12/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0181 - accuracy: 0.9920\n",
            "Epoch 13/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0105 - accuracy: 0.9941\n",
            "Epoch 14/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0100 - accuracy: 0.9937\n",
            "Epoch 15/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0094 - accuracy: 0.9945\n",
            "Epoch 16/75\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0081 - accuracy: 0.9947\n",
            "Epoch 17/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0080 - accuracy: 0.9951\n",
            "Epoch 18/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0077 - accuracy: 0.9950\n",
            "Epoch 19/75\n",
            "612/612 [==============================] - 15s 25ms/step - loss: 0.0076 - accuracy: 0.9952\n",
            "Epoch 20/75\n",
            "612/612 [==============================] - 19s 30ms/step - loss: 0.0084 - accuracy: 0.9948\n",
            "Epoch 21/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0106 - accuracy: 0.9944\n",
            "Epoch 22/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0121 - accuracy: 0.9940\n",
            "Epoch 23/75\n",
            "612/612 [==============================] - 14s 24ms/step - loss: 0.0097 - accuracy: 0.9946\n",
            "Epoch 24/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0076 - accuracy: 0.9955\n",
            "Epoch 25/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0074 - accuracy: 0.9954\n",
            "Epoch 26/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0075 - accuracy: 0.9950\n",
            "Epoch 27/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0079 - accuracy: 0.9951\n",
            "Epoch 28/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0082 - accuracy: 0.9955\n",
            "Epoch 29/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0125 - accuracy: 0.9943\n",
            "Epoch 30/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0113 - accuracy: 0.9944\n",
            "Epoch 31/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0102 - accuracy: 0.9947\n",
            "Epoch 32/75\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0076 - accuracy: 0.9952\n",
            "Epoch 33/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0076 - accuracy: 0.9952\n",
            "Epoch 34/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0078 - accuracy: 0.9956\n",
            "Epoch 35/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0073 - accuracy: 0.9953\n",
            "Epoch 36/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0073 - accuracy: 0.9956\n",
            "Epoch 37/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0073 - accuracy: 0.9956\n",
            "Epoch 38/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0071 - accuracy: 0.9955\n",
            "Epoch 39/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0071 - accuracy: 0.9953\n",
            "Epoch 40/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0073 - accuracy: 0.9957\n",
            "Epoch 41/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0081 - accuracy: 0.9952\n",
            "Epoch 42/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0071 - accuracy: 0.9956\n",
            "Epoch 43/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0071 - accuracy: 0.9959\n",
            "Epoch 44/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0071 - accuracy: 0.9958\n",
            "Epoch 45/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0069 - accuracy: 0.9952\n",
            "Epoch 46/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0072 - accuracy: 0.9955\n",
            "Epoch 47/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9954\n",
            "Epoch 48/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0087 - accuracy: 0.9952\n",
            "Epoch 49/75\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0091 - accuracy: 0.9952\n",
            "Epoch 50/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0086 - accuracy: 0.9955\n",
            "Epoch 51/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9960\n",
            "Epoch 52/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0068 - accuracy: 0.9958\n",
            "Epoch 53/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0069 - accuracy: 0.9958\n",
            "Epoch 54/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0071 - accuracy: 0.9957\n",
            "Epoch 55/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9959\n",
            "Epoch 56/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9957\n",
            "Epoch 57/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9955\n",
            "Epoch 58/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9953\n",
            "Epoch 59/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0070 - accuracy: 0.9957\n",
            "Epoch 60/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0093 - accuracy: 0.9952\n",
            "Epoch 61/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0069 - accuracy: 0.9955\n",
            "Epoch 63/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9959\n",
            "Epoch 64/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0069 - accuracy: 0.9957\n",
            "Epoch 65/75\n",
            "612/612 [==============================] - 14s 23ms/step - loss: 0.0069 - accuracy: 0.9959\n",
            "Epoch 66/75\n",
            "612/612 [==============================] - 15s 24ms/step - loss: 0.0068 - accuracy: 0.9958\n",
            "Epoch 67/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9958\n",
            "Epoch 68/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0069 - accuracy: 0.9958\n",
            "Epoch 69/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0070 - accuracy: 0.9959\n",
            "Epoch 70/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0069 - accuracy: 0.9959\n",
            "Epoch 71/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0072 - accuracy: 0.9958\n",
            "Epoch 72/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0084 - accuracy: 0.9955\n",
            "Epoch 73/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0073 - accuracy: 0.9956\n",
            "Epoch 74/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0068 - accuracy: 0.9955\n",
            "Epoch 75/75\n",
            "612/612 [==============================] - 14s 22ms/step - loss: 0.0085 - accuracy: 0.9960\n",
            "204/204 [==============================] - 3s 8ms/step - loss: 1.3349 - accuracy: 0.8838\n",
            "test accuracy is:  [1.3348597288131714, 0.8837957978248596]\n",
            "204/204 [==============================] - 3s 7ms/step\n",
            "The confusion matrix is [[4936  424]\n",
            " [ 334  829]]\n",
            "Accuracy: 0.884\n",
            "Recall: 0.713\n",
            "Precision: 0.662\n",
            "F1 Score: 0.686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EL0YW2KwmmAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}